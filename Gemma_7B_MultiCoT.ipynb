{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90a87d4",
   "metadata": {
    "papermill": {
     "duration": 0.003656,
     "end_time": "2024-08-04T20:05:30.953572",
     "exception": false,
     "start_time": "2024-08-04T20:05:30.949916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook illustrates the agent creation process for the **LLM 20 Questions**. Running this notebook produces a `submission.tar.gz` file. You may submit this file directly from the **Submit to competition** heading to the right. Alternatively, from the notebook viewer, click the *Output* tab then find and download `submission.tar.gz`. Click **Submit Agent** at the upper-left of the competition homepage to upload your file and make your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd295ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T20:05:30.961343Z",
     "iopub.status.busy": "2024-08-04T20:05:30.961043Z",
     "iopub.status.idle": "2024-08-04T20:05:44.037060Z",
     "shell.execute_reply": "2024-08-04T20:05:44.036264Z"
    },
    "papermill": {
     "duration": 13.082356,
     "end_time": "2024-08-04T20:05:44.039271",
     "exception": false,
     "start_time": "2024-08-04T20:05:30.956915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'gemma_pytorch'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /kaggle/working\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null\n",
    "mkdir /kaggle/working/submission/lib/gemma/\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7a0a1",
   "metadata": {
    "papermill": {
     "duration": 0.003238,
     "end_time": "2024-08-04T20:05:44.046112",
     "exception": false,
     "start_time": "2024-08-04T20:05:44.042874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e74b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T20:05:44.054984Z",
     "iopub.status.busy": "2024-08-04T20:05:44.054709Z",
     "iopub.status.idle": "2024-08-04T20:05:44.085864Z",
     "shell.execute_reply": "2024-08-04T20:05:44.084917Z"
    },
    "papermill": {
     "duration": 0.03827,
     "end_time": "2024-08-04T20:05:44.087707",
     "exception": false,
     "start_time": "2024-08-04T20:05:44.049437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission/main.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib/gemma'))\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))\n",
    "else:\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib/gemma\")\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib/\")\n",
    "\n",
    "from typing import Iterable\n",
    "from typing import Any, List, Optional, Sequence, Tuple, Union\n",
    "from ast import parse\n",
    "import contextlib, time, random, itertools, re\n",
    "import torch\n",
    "import gemma\n",
    "from gemma.config import get_config_for_7b, get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM, GemmaModel\n",
    "\n",
    "\n",
    "VARIANT = '7b-it-quant'\n",
    "MACHINE_TYPE = 'cuda'\n",
    "ENV = 'kaggle'\n",
    "agent = None\n",
    "temperature = 1\n",
    "\n",
    "\n",
    "# configering setting\n",
    "sys_prompt_guesser = 'You are an AI assistant designed to play the 20 Questions game. \\\n",
    "In each round of the game, choose an attribute most likely to aid your deduction and ask a yes-no question based on it. \\\n",
    "Your response should be generated with step-by-step reasoning. Ensure that the question you generate has not been asked before and that its attribute is not shown in the known information list. Consider whether this attribute or a similar question has been asked before selecting key attributes. \\\n",
    "An unavailable question will cause seriouse problem so think more thoroughly before responsing. \\\n",
    "Once you believe that the key attribute is available, the most helpful attribute among effective ones provides the maximum information gain, meaning it significantly reduces the entropy of your guess, regardless of whether the answer is **yes** or **no**. Finally using this attribute, ask a question in English. \\\n",
    "Here are few examples of how you use come up with a formatted response with reasoning, remember they are just examples, please do not imitate its asking strategy:'\n",
    "\n",
    "sys_prompt_answerer = f'You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing. Here is an example of answering a yes-no question:'\n",
    "\n",
    "few_shot_examples_answerer = [\n",
    "    \n",
    "'''\n",
    "The keyword is Sydney in the category place. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.\n",
    "\n",
    "''',\n",
    "     \n",
    "'''\n",
    "Question: Is it a place?\n",
    "**yes**\n",
    "Sydney is a city, which is a type of place. This is why the answer to the question \"Is it a place?\" is yes.\n",
    "''',\n",
    "     \n",
    "'''\n",
    "Question: Is it located in the Southern Hemisphere?\n",
    "**yes**\n",
    "Sydney is a city in Australia, which is in the Southern Hemisphere. Therefore, the answer to your question is yes.\n",
    "''',\n",
    "     \n",
    "'''\n",
    "Question: Is it a capital city?\n",
    "**no**\n",
    "Although Sydney is a major city in Australia, the capital city of Australia is Canberra. Therefore, the answer to your question is no.\n",
    "''',\n",
    "     \n",
    "     \n",
    "'''\n",
    "Question: Is it a well-known tourism city?\n",
    "**yes**\n",
    "Sydney is famous for its landmarks such as the Sydney Opera House, the Harbour Bridge, and its beautiful beaches, making it a major tourist destination. Therefore, the answer to your question is yes.\n",
    "'''\n",
    "                              \n",
    "]\n",
    "\n",
    "few_shot_examples_ask = [\n",
    "    \n",
    "[# Round 1 | Keyword: Yangtze River\n",
    "'''\n",
    "Known information: [\"is it a country? --> no\", \"is it a city? --> no\"]\n",
    "**Key attribute**: \"man-made structure\" \n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is it a man-made structure?\" \n",
    "**Reasoning**:\n",
    "since following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \n",
    "Man-made vs. Natural: This question helps to differentiate between natural landmarks (e.g., Grand Canyon) and man-made structures (e.g., Eiffel Tower). \n",
    "Broad Categories: Man-made structures include a wide range of possibilities (e.g., buildings, monuments), whereas cities are all man-made but represent a different category. \n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\"]\n",
    "**Key attribute**: \"in Asia\" \n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is it located in Asia?\" \n",
    "**Reasoning**:\n",
    "since following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \n",
    "Geographic Focus: Identifying the continent will significantly narrow down the possible natural landmarks. \n",
    "Large Landmarks: Asia has several major natural landmarks (e.g., Mount Everest, Great Wall).\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\", \"is it a river? --> yes\"]\n",
    "**Key attribute**: \"longest river in China\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is it the longest river in China?\"\n",
    "**Reasoning**:\n",
    "since following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \n",
    "Length-Specific Focus: Knowing whether it is the longest river will help confirm or eliminate the Yangtze River.\n",
    "Major Rivers: The Yangtze River is the longest river in China, followed by the Yellow River.\n",
    "Effective Split: This question will help confirm or deny one of the most prominent landmarks in China, providing a clear yes/no split.\n",
    "'''],\n",
    "\n",
    "\n",
    "[# Round 2 | Keyword: Congo\n",
    "'''\n",
    "Known information: [\"is it a country? --> yes\"]\n",
    "**Key attribute**: \"in Europe\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this country in Europe?\"\n",
    "**Reasoning**:\n",
    "since following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \n",
    "Continental Focus: Knowing the continent will help significantly narrow down the list of possible countries.\n",
    "Effective Reduction: Europe has many countries, so confirming or eliminating Europe will reduce the search space.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a country? --> yes\", \"is it in Europe? --> no\", \"is it in Asia? --> no\", \"is it in Africa? --> yes\", \"is it in Northern Africa? --> no\", \"is it in Eastern Africa? --> no\", \"is it in Western Africa? --> no\", \"is it in Southern Africa? --> yes\"]\n",
    "**Key attribute**: \"landlocked country\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this country landlocked?\"\n",
    "**Reasoning**:\n",
    "To further narrow down the possibilities within Southern Africa, I will focus on another well-known country in that region.\n",
    "Geographical Focus: Knowing whether the country is landlocked will significantly narrow down the possibilities within Southern Africa.\n",
    "Effective Reduction: There are several landlocked countries in Southern Africa, so confirming or eliminating this will help focus the search.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a country? --> yes\", \"is it in Europe? --> no\", \"is it in Asia? --> no\", \"is it in Africa? --> yes\", \"is it in Northern Africa? --> no\", \"is it in Eastern Africa? --> no\", \"is it in Western Africa? --> no\", \"is it in Southern Africa? --> yes\", \"is it landlocked? --> no\", \"is Portuguese its an official language? --> no\"]\n",
    "**Key attribute**: \"borders the Indian Ocean\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Does this country border the Indian Ocean?\"\n",
    "**Reasoning**:\n",
    "since following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \n",
    "Geographic Focus: Knowing whether the country borders the Indian Ocean can help narrow down the options.\n",
    "Balanced Distribution: This question provides a clear yes/no split, effectively narrowing down the search.\n",
    " '''],\n",
    " \n",
    "[# round 3 | Keyword: Ryan \n",
    "'''\n",
    "Known information: [\"is it a place? --> no\", \"is it a person? --> yes\"]\n",
    "**Key attribute**: \"a historical figure\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this person a historical figure?\"\n",
    "**Reasoning**:\n",
    "Time Frame: Identifying whether the person is historical can significantly narrow down the possibilities.\n",
    "Balanced Distribution: This question provides a clear yes/no split, guiding the search effectively.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a place? --> no\", \"is it a person? --> yes\", \"is it a historical figure? --> no\", \"is it involved in the entertainment industry? --> yes\", \"is it primarily known for their work in music? --> no\", \"is it primarily known for their work as an actor? --> yes\", \"has it won an Academy Award (Oscar)? --> no\"]\n",
    "**Key attribute**: \"primarily known for television work\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this person primarily known for their work in television?\"\n",
    "**Reasoning**:\n",
    "Medium Focus: Identifying whether the person is known for television can help narrow down the possibilities.\n",
    "Balanced Distribution: This question provides a clear yes/no split, effectively guiding the search.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a place? --> no\", \"is it a person? --> yes\", \"is it a historical figure? --> no\", \"is it involved in the entertainment industry? --> yes\", \"is it primarily known for their work in music? --> no\", \"is it primarily known for their work as an actor? --> yes\", \"has it won an Academy Award (Oscar)? --> no\", \"is it primarily known for their work in television? --> no\", \"is it primarily known for their work in action movies? --> yes\", \"is it associated with a major action movie franchise? --> yes\"]\n",
    "**Key attribute**: \"known for science fiction action movies\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this person known for their work in science fiction action movies?\"\n",
    "**Reasoning**:\n",
    "Genre Specificity: Identifying whether the person is known for science fiction action movies can help narrow down the possibilities.\n",
    "Effective Reduction: This helps distinguish between different types of action movie genres, such as sci-fi, fantasy, or military.\n",
    "'''],\n",
    "\n",
    "[# round 4 | Keyword: Noosa\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\"]\n",
    "**Key attribute**: \"a capital city\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is it a capital city?\"\n",
    "**Reasoning**:\n",
    "Geographic Focus: This question helps determine if the city is a capital, significantly narrowing the possibilities.\n",
    "Effective Reduction: If the answer is yes, it focuses on capital cities, eliminating all non-capital cities. If no, it eliminates all capital cities from consideration.\n",
    "Context Relevance: Knowing whether the city is a capital helps tailor subsequent questions to specific types of cities.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes.\"]\n",
    "**Key attribute**: \"in the Southern Hemisphere\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this city in the Southern Hemisphere?\"\n",
    "**Reasoning**:\n",
    "Hemispheric Focus: This question splits the world into two large, nearly equal parts, effectively narrowing down possibilities.\n",
    "Balanced Distribution: The Earth is divided evenly by the equator, providing a clear yes/no split that maximizes information gain.\n",
    "''',\n",
    "\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes\", \"is it in Africa? --> no\", \"is it in South America? --> no\", \"is it in Australia or Oceania? --> yes\", \"is it in Australia? --> yes\", \"is it a coastal city? --> yes\"]\n",
    "**Key attribute**: \"a well-known tourist destination\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this city a well-known tourist destination?\"\n",
    "**Reasoning**:\n",
    "Tourism Focus: This question helps determine if the city is popular with tourists, which can narrow down the list of coastal cities.\n",
    "Effective Reduction: If the answer is yes, it focuses on well-known tourist cities, eliminating less-known cities. If no, it narrows down to less-touristic coastal cities.\n",
    "Context Relevance: Many of Australia's coastal cities are also popular tourist destinations, making this an important distinction.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes\", \"is it in Africa? --> no\", \"is it in South America? --> no\", \"is it in Australia or Oceania? --> yes\", \"is it in Australia? --> yes\", \"is it a coastal city? --> yes, \"is a well-known tourist destination? --> yes\", \"is it Gold Coast? --> no\", \"is it in New South Wales? --> no\", \"is it in Queensland? --> yes\", \"is it associated with the Great Barrier Reef? --> no\"]\n",
    "**Key attribute**: \"popular for its beaches\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this city popular for its beaches?\"\n",
    "**Reasoning**:\n",
    "Tourism Focus: Identifying if the city is known for its beaches can help narrow down the possibilities.\n",
    "Context Relevance: Many coastal cities in Queensland are known for their beaches, making this a significant distinction.\n",
    "Balanced Distribution: Coastal versus inland tourist destinations provide a clear yes/no split.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes\", \"is it in Africa? --> no\", \"is it in South America? --> no\", \"is it in Australia or Oceania? --> yes\", \"is it in Australia? --> yes\", \"is it a coastal city? --> yes, \"is a well-known tourist destination? --> yes\", \"is it Gold Coast? --> no\", \"is it in New South Wales? --> no\", \"is it in Queensland? --> yes\", \"is it associated with the Great Barrier Reef? --> no\", \"is it popular for its beaches? --> yes\"]\n",
    "**Key attribute**: \"located on the Sunshine Coast\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is this city located on the Sunshine Coast?\"\n",
    "**Reasoning**:\n",
    "Regional Focus: Identifying if the city is on the Sunshine Coast can significantly narrow down the possibilities.\n",
    "Context Relevance: The Sunshine Coast is known for its beach destinations, making this a significant distinction.\n",
    "'''],\n",
    "\n",
    "[# round 5 | Keyword: Gym Mat\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> no\", \"is it a thing? --> yes\"]\n",
    "**Key attribute**: \"a technological device\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is it a technological device?\"\n",
    "**Reasoning**:\n",
    "Category Specificity: Identifying whether the thing is a technological device helps narrow down the possibilities.\n",
    "Effective Reduction: This helps focus on a specific type of thing.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> no\", \"is it a thing? --> yes\", \"is it a technological device? --> no\"]\n",
    "**Key attribute**: \"found in nature\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is it something found in nature?\"\n",
    "**Reasoning**:\n",
    "Category Specificity: Identifying whether the thing is natural helps narrow down the possibilities.\n",
    "Balanced Distribution: This question provides a clear yes/no split, guiding the search effectively.\n",
    "''',\n",
    "\n",
    "'''\n",
    "Known information: [\"is it a person? --> no\", \"is it a place? --> no\", \"is it a thing? --> yes\", \"is it a technological device? --> no\", \"can it be found in nature? --> no\"]\n",
    "**Key attribute**: \"found in households\"\n",
    "**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n",
    "**Question**: \"Is it something found in households?\"\n",
    "**Reasoning**:\n",
    "Category Specificity: Identifying whether the thing is commonly found in households helps narrow down the possibilities.\n",
    "Effective Reduction: This helps focus on a specific type of man-made object.\n",
    "Balanced Distribution: This question provides a clear yes/no split, guiding the search effectively.\n",
    "''']\n",
    "]\n",
    "\n",
    "few_shot_examples_guess = [\n",
    "'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\"]\\n\\\n",
    "Given these clues, it is likely a natural landmark rather than a city or a man-made structure. An example of a well-known natural landmark is the Grand Canyon.\\\n",
    "Guess: \"Grand Canyon\"'\n",
    "\n",
    "'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\"]\\n\\\n",
    "Given these clues, it is likely a natural landmark outside North America. An example of a famous natural landmark outside North America is Mount Everest.\\\n",
    "Guess: \"Mount Everest\"'\n",
    " \n",
    "'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\"]\\n\\\n",
    "Given these clues, it is likely a natural landmark in Asia. A famous natural landmark in Asia is the Himalayas.\\\n",
    "Guess: \"the Himalayas\"'\n",
    " \n",
    "'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\"]\\n\\\n",
    "Given these clues, it is likely a famous natural landmark in China. An example of such a landmark is the Mekong River.\\\n",
    "Guess: \"the Mekong River\"'\n",
    " \n",
    "'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\"]\\n\\\n",
    "Given these clues, it is likely a natural landmark in China that is not a mountain. An example of such a landmark could be the Tianchi Lake.\\\n",
    "Guess: \"the Tianchi Lake\"'\n",
    " \n",
    "'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\", \"is it a river? --> yes\"]\\n\\\n",
    "Given these clues, a very famous river in China is the Yellow River.\\\n",
    "Guess: \"the Yellow River\"',\n",
    "                          \n",
    "'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\", \"is it a river? --> yes\", \"is it the longest river in China? --> yes\"]\\n\\\n",
    "Given these clues, it should be the longest river in China which is the Yangtze River.\\\n",
    "Guess: \"the Yangtze River\"']\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "  torch.set_default_dtype(dtype)\n",
    "  yield\n",
    "  torch.set_default_dtype(torch.float)\n",
    "\n",
    "def interleave_unequal(x, y):\n",
    "    '''\n",
    "        Interleave two lists of unequal length.\n",
    "    '''\n",
    "    return [\n",
    "        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n",
    "    ]\n",
    "\n",
    "\n",
    "# Formatter Definition\n",
    "class PromptFormatter:\n",
    "    \n",
    "    '''\n",
    "        formatter class to format the prompt text for the model. \n",
    "        A general idea is \n",
    "    '''\n",
    "    \n",
    "    _start_token = '<start_of_turn>'\n",
    "    _end_token = '<end_of_turn>'\n",
    "        \n",
    "    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n",
    "        self._system_prompt = system_prompt\n",
    "        self._few_shot_examples = few_shot_examples\n",
    "        self._template_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n",
    "        self._template_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n",
    "        self._all_prompt = ''\n",
    "        # if sample_num is not None:\n",
    "        #   self.sample_num = sample_num\n",
    "        # elif self._few_shot_examples is not None:\n",
    "        #   self.sample_num = len(few_shot_examples)\n",
    "        # else:\n",
    "        #   self.sample_num = None\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self._all_prompt\n",
    "        \n",
    "    def reset(self):\n",
    "        self._all_prompt = ''\n",
    "        # if system prompt is provided, add it to the prompt\n",
    "        if self._system_prompt is not None:\n",
    "            self._all_prompt += self._template_user.format(self._system_prompt)\n",
    "        # same for few shot examples\n",
    "        if self._few_shot_examples is not None:\n",
    "            # self.add_rounds(self._few_shot_examples, start_agent='user')\n",
    "            self.add_new_round('user', 'Here are some examples of analyzing with causal reasoning:', True)\n",
    "            # for example in random.sample(self._few_shot_examples, self.sample_num):\n",
    "            for example in self._few_shot_examples:\n",
    "                self.add_new_round('model', example.strip(), True)\n",
    "            \n",
    "        \n",
    "    def add_user_round(self, user_prompt: str):\n",
    "        # add user round to the prompt\n",
    "        self._all_prompt += self._template_user.format(user_prompt)\n",
    "\n",
    "    def add_agent_round(self, model_response: str):\n",
    "        self._all_prompt += self._template_model.format(model_response)\n",
    "    \n",
    "    def add_rounds(self, rounds: Iterable, start_agent: str):\n",
    "        '''\n",
    "            Apply a sequence of rounds to the formatter, starting with the specified agent.\n",
    "        '''\n",
    "        formatters = [self.add_agent_round, self.add_user_round] if start_agent == 'model' else [self.add_user_round, self.add_agent_round] # here, self.model and self.user are functions definded above\n",
    "        formatters = itertools.cycle(formatters)\n",
    "        for fmt, round in zip(formatters, rounds):\n",
    "            fmt(round)\n",
    "        return self\n",
    "    \n",
    "    # def add_end_token(self):\n",
    "    #     self._all_prompt += f\"{self._end_token}\\n\"\n",
    "    \n",
    "    def add_new_round(self, player: str, prompt:str = None, end_token: bool = False):\n",
    "        self._all_prompt += f\"{self._start_token}{player}\\n\"\n",
    "        if prompt is not None:\n",
    "            self._all_prompt += f'{prompt}'\n",
    "        if end_token:\n",
    "            # self.add_end_token()\n",
    "            self._all_prompt += f\"{self._end_token}\\n\"\n",
    "    \n",
    "    def formate_MCQA(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "# print(str(PromptFormatter(sys_prompt, few_shot_examples_ask)))\n",
    "        \n",
    "# Agent Definition\n",
    "class GemmaAgent:\n",
    "    def __init__(self, model_variant, device='cuda:0', env=\"kaggle\", output_len=200, system_prompt=None, few_shot_examples=None):\n",
    "        # model initialization\n",
    "        self.device = device\n",
    "        self.model_variant = model_variant\n",
    "        \n",
    "        WEIGHTS_PATH = self._set_up_env(env)\n",
    "                \n",
    "        # Ensure that the tokenizer is present\n",
    "        tokenizer_path = os.path.join(WEIGHTS_PATH, 'tokenizer.model')\n",
    "        assert os.path.isfile(tokenizer_path), 'Tokenizer not found!'\n",
    "        \n",
    "        # Ensure that the checkpoint is present\n",
    "        ckpt_path = os.path.join(WEIGHTS_PATH , f'gemma-{model_variant}.ckpt')\n",
    "        assert os.path.isfile(ckpt_path), 'PyTorch checkpoint not found!'\n",
    "\n",
    "        # loading model configuration\n",
    "        model_config = get_config_for_2b() if \"2b\" in model_variant else get_config_for_7b()\n",
    "        model_config.quant = \"quant\" in model_variant\n",
    "        model_config.tokenizer = os.path.join(WEIGHTS_PATH, \"tokenizer.model\")\n",
    "        \n",
    "        with _set_default_tensor_type(model_config.get_dtype()):\n",
    "            self.model = GemmaForCausalLM(model_config)\n",
    "            self.model.load_weights(ckpt_path)\n",
    "            self.model = self.model.to(self.device).eval()\n",
    "            \n",
    "        self.round_num = 0\n",
    "        self.known_info = []\n",
    "        self.last_key_attribute = None\n",
    "        self.last_guess = None\n",
    "        self.output_len = output_len\n",
    "        \n",
    "        # formatter arguments   \n",
    "        self.system_prompt = system_prompt\n",
    "        self.few_shot_examples = few_shot_examples\n",
    "\n",
    "    def _set_up_env(self, env):\n",
    "        \n",
    "        if env == 'kaggle':\n",
    "            print(\"Loading model in Kaggle, model weights will be searched within local directories.\")\n",
    "            \n",
    "            # kaggle configuration\n",
    "            KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "            if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "                WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, f\"gemma/pytorch/{self.model_variant}/2\")\n",
    "            else:\n",
    "                WEIGHTS_PATH = f\"/kaggle/input/gemma/pytorch/{self.model_variant}/2\"\n",
    "                            \n",
    "        elif env == 'colab':\n",
    "            print(\"Loading model in Colab, starting from downloading the model weights.\")\n",
    "            \n",
    "            WEIGHTS_PATH = kagglehub.model_download(f'google/gemma/pyTorch/{self.model_variant}')\n",
    "        else:\n",
    "            raise ValueError(\"Argument 'env' should be in ['kaggle', 'colab']\")\n",
    "\n",
    "        return WEIGHTS_PATH\n",
    "\n",
    "    def _parse_response(self, response : str):\n",
    "      raise NotImplementedError\n",
    "  \n",
    "    def _format_prompt(self, obs):\n",
    "      raise NotImplementedError\n",
    "\n",
    "\n",
    "class GemmaAgent_Answer(GemmaAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # set up few_shot_examples\n",
    "        self.formatter = PromptFormatter(system_prompt=self.system_prompt,\n",
    "                                        few_shot_examples=self.few_shot_examples)\n",
    "\n",
    "    def _parse_response(self, response : str):\n",
    "        pattern = re.compile(r'\\*\\*([^*]+)\\*\\*', re.DOTALL)\n",
    "        matches = pattern.findall(response.lower())\n",
    "        \n",
    "        flag_no = 'no' in matches\n",
    "        flag_yes = 'yes' in matches\n",
    "        \n",
    "        # if both yes and no are in the response, randomly choose one\n",
    "        if flag_no and not flag_yes:\n",
    "            ret = 'no'\n",
    "        elif flag_yes and not flag_no:\n",
    "            ret = 'yes'\n",
    "        else:\n",
    "            ret = random.choice(['yes', 'no'])\n",
    "        \n",
    "        return ret\n",
    "\n",
    "    def _format_prompt(self, obs):\n",
    "        self.formatter.reset()\n",
    "        self.formatter.add_new_round('user', f'Remember how to use CoT as above and the format of answering. Now let us play 20 Questions. You are playing the role of the Answerer. The keyword is {obs[\"keyword\"]} in the category {obs[\"category\"]}.', True)\n",
    "        # add played rounds\n",
    "        rounds = interleave_unequal(obs[\"questions\"], obs[\"answers\"])\n",
    "        self.formatter.add_rounds(rounds, start_agent='user')\n",
    "        self.formatter.add_new_round('user', \n",
    "                                     f'The keyword is {obs[\"keyword\"]} in the category {obs[\"category\"]}. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.', \n",
    "                                     True)\n",
    "        # start of model response\n",
    "        self.formatter.add_new_round('model', f'Question: {obs[\"questions\"][-1]}', False)\n",
    "        \n",
    "    def __call__(self, obs, cfg=None):\n",
    "        print(obs['questions'])\n",
    "        self._format_prompt(obs)\n",
    "        prompt = str(self.formatter)\n",
    "        # print(prompt)\n",
    "        response = self.model.generate(prompt, device=self.device, output_len=self.output_len)\n",
    "        print(f'===> Turn Type: {obs[\"turnType\"]}\\nResponse: {response}')\n",
    "        return self._parse_response(response)\n",
    "\n",
    "\n",
    "class GemmaAgent_Guesser(GemmaAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # start = time.time()\n",
    "        # set up general configurations\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # set up few_shot_examples\n",
    "        self.few_shot_exmaples_ask = self.few_shot_examples[0]\n",
    "        self.few_shot_exmaples_guess = self.few_shot_examples[1]\n",
    "        # agent args\n",
    "        self.formatter = PromptFormatter(system_prompt=self.system_prompt, \n",
    "                                        few_shot_examples=self.few_shot_exmaples_guess)\n",
    "        # print(f'Initialization Time: {time.time()-start}s')\n",
    "        self.categories = ['person', 'thing', 'place']\n",
    "\n",
    "        \n",
    "    \n",
    "    def _parse_response(self, response : str):\n",
    "        '''\n",
    "            parse the response into a dictionary.\n",
    "            may contain three keys: key_attribute, question, guess and their value respectively.\n",
    "            e.g.: {\"key_attribute\": 'a country', \"question\": 'Is it a country?'} for a parsed asker response.\n",
    "        '''\n",
    "        pattern = re.compile(r'\\*\\*([^*]+)\\*\\*:?\\s*(.*?)(?=\\*\\*|$)', re.DOTALL)\n",
    "        matches = pattern.findall(response.lower())\n",
    "        parse_dict = {'key attribute':None, 'question':None, 'guess':None}\n",
    "        for k, v in matches:\n",
    "            v = v.strip('\\n\\'\\\"')\n",
    "            if ('attr' in k) and (parse_dict['key attribute'] == None):\n",
    "                parse_dict['key attribute'] = v\n",
    "            elif ('ques' in k) and (parse_dict['question'] == None):\n",
    "                parse_dict['question'] = v\n",
    "            elif ('guess' in k) and (parse_dict['guess'] == None):\n",
    "                parse_dict['guess'] = v\n",
    "\n",
    "        return parse_dict\n",
    "    \n",
    "    def _format_prompt(self, obs):\n",
    "        if obs[\"turnType\"] == 'ask':\n",
    "          self.formatter._few_shot_examples = random.choice(self.few_shot_exmaples_ask)\n",
    "        if obs[\"turnType\"] == 'guess':\n",
    "          self.formatter._few_shot_examples = self.few_shot_exmaples_guess\n",
    "        # reset formatter\n",
    "        self.formatter.reset()\n",
    "        self.formatter.add_new_round('user', 'Remember how to use CoT as above and the format of answering, now let us play a new game from the begining.', True)\n",
    "        # add played rounds\n",
    "        rounds = interleave_unequal(obs[\"questions\"], obs[\"answers\"])\n",
    "        self.formatter.add_rounds(rounds, start_agent='model')\n",
    "        if obs[\"turnType\"] == 'ask':\n",
    "            self.formatter.add_new_round('user', \n",
    "                                         'Now it is your turn to ask a question. Please construct a new question with chain of thought. Please consider **redundent attribute** step by step and ensure that your chosen attribute is not redundent, which means that your attribute is not redundent and should not be asked before. Baiscally it should follows the format within 100 words as following: **Key attribute**:\"a summarized attribute about your question\"\\n**Redundent**:\"whether and why it is a key attribute that you have not asked before\"\\n**Question**:\"a yes-no question deducted from your reasoning\"\\n**Reasoning**:\"your reasoning about why this attribute is avaliable and the most helpful\"', \n",
    "                                         True)\n",
    "        elif obs[\"turnType\"] == 'guess':\n",
    "            self.formatter.add_new_round('user', \n",
    "                                         'Now guess the keyword based on your analysis with reasoning and known information. And surround a pointer of guess with double asterisks (**?**) and your guessed keyword with doublr quotation markers (\"?\") in the end, such as **Guess** \"your guess\"', \n",
    "                                         True)\n",
    "        # start of model response\n",
    "        self.formatter.add_new_round('model', f'Given information: {str(self.known_info)}', False)                \n",
    "\n",
    "    def __call__(self, obs, cfg=None):\n",
    "        '''\n",
    "            Main function to interact with the model. \n",
    "                1. update known information based on the observation and round number\n",
    "                2. format the prompt with the observation\n",
    "                3. generate response from the model\n",
    "                4. parse the response and update information if needed\n",
    "        '''\n",
    "\n",
    "        if obs[\"turnType\"] == 'ask': \n",
    "            print(f\"=========== round: {self.round_num} | last key attr: {self.last_key_attribute}===========\")\n",
    "            self.round_num += 1\n",
    "            \n",
    "            # the category still remains unknown\n",
    "            if isinstance(self.categories, list) and len(self.categories) > 1:\n",
    "                # for the first round, randomly choose an attribute as initialization\n",
    "                self.last_key_attribute = random.choice(self.categories)\n",
    "                # kick out the selected key attribute from the categories\n",
    "                self.categories = list(set(self.categories) - set([self.last_key_attribute]))\n",
    "                response = f'Is it a {self.last_key_attribute}?'\n",
    "                return response\n",
    "            \n",
    "            # Formatting prompt with observations\n",
    "            self._format_prompt(obs)\n",
    "            prompt = str(self.formatter)\n",
    "            # debug\n",
    "            print(f\"===> Turn Type: {obs['turnType']}\")\n",
    "            print(\"==> Known Info:\", self.known_info)\n",
    "            # Getting response from LLM\n",
    "            response = self.model.generate(prompt, device=self.device, output_len=self.output_len)   \n",
    "            print(f'=> Response: {response}')\n",
    "            \n",
    "            # parse response and update information if needed\n",
    "            parse_dict = self._parse_response(response)\n",
    "            # print(f'\\nParse_dict: {parse_dict}')\n",
    "            # if in an ask turn, try to grab the key attribute from the response and update last key attribute for the next information updating\n",
    "            # successfully grab the key attribute from the response\n",
    "            if parse_dict['key attribute']:\n",
    "                last_key_attribute = parse_dict['key attribute'].lower()\n",
    "                last_key_attribute = last_key_attribute.replace('is not ', '')\n",
    "                last_key_attribute = last_key_attribute.replace('is ', '')\n",
    "                self.last_key_attribute = last_key_attribute\n",
    "            # no key attribute parsed from the response, directly use question as key attribute\n",
    "            elif parse_dict['question']:\n",
    "                self.last_key_attribute  = parse_dict['question']\n",
    "                ret = parse_dict['question']\n",
    "                return ret\n",
    "            # worst case, there is neither key attribute nor question parsed from the response, randomly choose an attribute\n",
    "            else:\n",
    "                random_alphabet = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "                ret = f'is it started with alphabet {random_alphabet}?'\n",
    "                self.last_key_attribute = f'started with alphabet {random_alphabet}'\n",
    "                return ret\n",
    "\n",
    "            # parsed response has question, use question as response\n",
    "            if parse_dict['question']:\n",
    "                ret = parse_dict['question']\n",
    "            # parsed response has no question but have key attribute, use key attribute as question\n",
    "            else:\n",
    "\n",
    "                ret = f'is it {self.last_key_attribute}?'   \n",
    "            return ret\n",
    "        # if in a guess turn, try to grab the guess from the response and update last guess for the next information updating\n",
    "        elif obs[\"turnType\"] == 'guess':\n",
    "            last_question = obs['questions'][-1]\n",
    "            # update information\n",
    "            if isinstance(self.categories, list) and len(self.categories) > 0:\n",
    "                # if it is the second round, grab the answer and update known information\n",
    "                last_answer = obs[\"answers\"][-1]\n",
    "                # can determine the category\n",
    "                if last_answer == 'yes':\n",
    "                    self.known_info.append(f'is it a {self.last_key_attribute}? --> yes')\n",
    "                    self.categories = self.last_key_attribute\n",
    "                # the category is the one left in the category list\n",
    "                elif len(self.categories) == 1:\n",
    "                    self.known_info.append(f'is it a {self.last_key_attribute}? --> no')\n",
    "                    self.categories = self.categories[0]\n",
    "                    self.known_info.append(f'is it a {self.categories}? --> yes')\n",
    "                # there are still more than one categories left\n",
    "                else:\n",
    "                    self.known_info.append(f'is it a {self.last_key_attribute}? --> no')                \n",
    "            else:\n",
    "                # other rounds, update known information\n",
    "                last_answer = obs['answers'][-1]\n",
    "                self.known_info.append(f'{last_question} --> {last_answer}')\n",
    "                # if last_answer == 'yes':\n",
    "                    # self.known_info.append(f'{last_question} --> yes')\n",
    "                # else:\n",
    "                    # self.known_info.append(f'is not {self.last_key_attribute}')\n",
    "            \n",
    "            # Formatting prompt with observations\n",
    "            self._format_prompt(obs)\n",
    "            prompt = str(self.formatter)\n",
    "            print(f\"===> Turn Type: {obs['turnType']}\")\n",
    "            print(\"==> Known Info:\", self.known_info)\n",
    "            \n",
    "            # print(\"++++++++++++++++++++++++++++++\\n\", prompt, \"\\n++++++++++++++++++++++++++++++\")\n",
    "            \n",
    "            # Getting response from LLM\n",
    "            response = self.model.generate(prompt, device=self.device, output_len=self.output_len)   \n",
    "            print(f'=> Response: {response}')\n",
    "            \n",
    "            # parse response and update information if needed\n",
    "            parse_dict = self._parse_response(response)\n",
    "            # print(f'\\nParse_dict: {parse_dict}')\n",
    "            if parse_dict['guess']:\n",
    "                self.last_guess = parse_dict['guess']\n",
    "                ret = parse_dict['guess']\n",
    "            # if there is no guess parsed from the response, return empty string\n",
    "            else:\n",
    "                ret = ''\n",
    "                \n",
    "            return ret\n",
    "        else:\n",
    "            raise ValueError('Invalid turnType.')\n",
    "    \n",
    "# Simulation API\n",
    "def get_agent(name):\n",
    "    global agent\n",
    "    \n",
    "    if agent is None and name == 'questioner':\n",
    "        agent = GemmaAgent_Guesser(model_variant=VARIANT, \n",
    "                                   device=MACHINE_TYPE, \n",
    "                                   env=ENV, \n",
    "                                   output_len=100, \n",
    "                                   system_prompt=sys_prompt_guesser, \n",
    "                                   few_shot_examples=[few_shot_examples_ask, few_shot_examples_guess])\n",
    "    elif agent is None and name == 'answerer':\n",
    "        agent = GemmaAgent_Answer(model_variant=VARIANT, \n",
    "                                  device=MACHINE_TYPE, \n",
    "                                  env=ENV, \n",
    "                                  output_len=50, \n",
    "                                  system_prompt=sys_prompt_answerer,\n",
    "                                  few_shot_examples=few_shot_examples_answerer)\n",
    "    assert agent is not None, 'Agent not found!'\n",
    "    return agent\n",
    "\n",
    "def get_fn(obs, config):\n",
    "#     start = time.time()\n",
    "\n",
    "    # print(f\"\\nStrp: {obs['step']}\")\n",
    "    # print(agent)\n",
    "\n",
    "    if obs['turnType'] == \"ask\":\n",
    "        response = get_agent('questioner')(obs)\n",
    "    elif obs['turnType'] == \"guess\":\n",
    "        response = get_agent('questioner')(obs)\n",
    "    elif obs['turnType'] == \"answer\":\n",
    "        response = get_agent('answerer')(obs)\n",
    "\n",
    "    if response is None or len(response) <= 1:\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        # print(f'TOTAL TIME: {time.time()-start}s')\n",
    "        # print(f'Turn Type: {obs[\"turnType\"]}\\nResponse: {response}')\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4d3b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T20:05:44.095641Z",
     "iopub.status.busy": "2024-08-04T20:05:44.095365Z",
     "iopub.status.idle": "2024-08-04T20:05:50.145408Z",
     "shell.execute_reply": "2024-08-04T20:05:50.144479Z"
    },
    "papermill": {
     "duration": 6.056456,
     "end_time": "2024-08-04T20:05:50.147574",
     "exception": false,
     "start_time": "2024-08-04T20:05:44.091118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!apt install pigz pv > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b9cdcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T20:05:50.156157Z",
     "iopub.status.busy": "2024-08-04T20:05:50.155841Z",
     "iopub.status.idle": "2024-08-04T20:08:14.903206Z",
     "shell.execute_reply": "2024-08-04T20:08:14.902109Z"
    },
    "papermill": {
     "duration": 144.754339,
     "end_time": "2024-08-04T20:08:14.905591",
     "exception": false,
     "start_time": "2024-08-04T20:05:50.151252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/pytorch/7b-it-quant/2"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "modelId": 3301,
     "modelInstanceId": 8749,
     "sourceId": 11359,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 166.833744,
   "end_time": "2024-08-04T20:08:15.139949",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-04T20:05:28.306205",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
