{"cells":[{"cell_type":"markdown","metadata":{},"source":["This notebook illustrates the agent creation process for the **LLM 20 Questions**. Running this notebook produces a `submission.tar.gz` file. You may submit this file directly from the **Submit to competition** heading to the right. Alternatively, from the notebook viewer, click the *Output* tab then find and download `submission.tar.gz`. Click **Submit Agent** at the upper-left of the competition homepage to upload your file and make your submission. "]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":13.257308,"end_time":"2024-04-17T13:47:49.310664","exception":false,"start_time":"2024-04-17T13:47:36.053356","status":"completed"},"tags":[]},"outputs":[],"source":["%%bash\n","cd /kaggle/working\n","pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece\n","git clone https://github.com/google/gemma_pytorch.git > /dev/null\n","mkdir /kaggle/working/submission/lib/gemma/\n","mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.016612,"end_time":"2024-04-17T13:47:49.33012","exception":false,"start_time":"2024-04-17T13:47:49.313508","status":"completed"},"tags":[]},"outputs":[],"source":["# %%writefile submission/main.py\n","# Setup\n","import os\n","import sys\n","\n","# **IMPORTANT:** Set up your system path like this to make your code work\n","# both in notebooks and in the simulations environment.\n","KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n","if os.path.exists(KAGGLE_AGENT_PATH):\n","    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))\n","else:\n","    sys.path.insert(0, \"/kaggle/working/submission/lib\")\n","\n","import contextlib\n","import os\n","import sys\n","from pathlib import Path\n","\n","#################################################################\n","\n","import torch\n","from gemma.config import get_config_for_7b, get_config_for_2b\n","from gemma.model import GemmaForCausalLM\n","\n","if os.path.exists(KAGGLE_AGENT_PATH):\n","    WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, \"gemma/pytorch/7b-it-quant/2\")\n","else:\n","    WEIGHTS_PATH = \"/kaggle/input/gemma/pytorch/7b-it-quant/2\"\n","\n","# Prompt Formatting\n","import itertools\n","from typing import Iterable\n","\n","\n","\n","\n","class GemmaFormatter:\n","    '''\n","        A formatter for the Gemma model that allows for easy construction of prompts,\n","        basically use __repr__ function and other functions to format the prompt\n","\n","        containing following members:\n","            self._system_prompt: str\n","            self._few_shot_examples: Iterable\n","            self._turn_user: str\n","            self._turn_model: str\n","            self._state: str\n","            self._start_token: str\n","            self._end_token: str\n","            self.user: function\n","            self.model: function\n","    '''\n","\n","    \n","    _start_token = '<start_of_turn>'\n","    _end_token = '<end_of_turn>'\n","\n","    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n","        self._system_prompt = system_prompt\n","        self._few_shot_examples = few_shot_examples\n","        self._turn_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n","        self._turn_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n","        self.reset()\n","\n","    def __repr__(self):\n","        '''\n","            repr funcion is used to return the string representation of the object\n","            here we retrun the state of the object\n","        '''\n","        return self._state\n","\n","    def user(self, prompt):\n","        '''\n","\n","        '''\n","        self._state += self._turn_user.format(prompt)\n","        return self\n","\n","    def model(self, prompt):\n","        self._state += self._turn_model.format(prompt)\n","        return self\n","\n","    def start_user_turn(self):\n","        self._state += f\"{self._start_token}user\\n\"\n","        return self\n","\n","    def start_model_turn(self):\n","        self._state += f\"{self._start_token}model\\n\"\n","        return self\n","\n","    def end_turn(self):\n","        self._state += f\"{self._end_token}\\n\"\n","        return self\n","\n","    def reset(self):\n","        '''\n","            in this function self._state is reset to empty string and will be modified by user() and model() functions\n","        '''\n","        self._state = \"\"\n","        if self._system_prompt is not None:\n","            self.user(self._system_prompt)\n","        if self._few_shot_examples is not None:\n","            self.apply_turns(self._few_shot_examples, start_agent='user')\n","        return self\n","\n","\n","    def apply_turns(self, turns: Iterable, start_agent: str):\n","        '''\n","        Apply a sequence of turns to the formatter, starting with the specified agent.\n","        '''\n","        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model] # here, self.model and self.user are functions definded above\n","        formatters = itertools.cycle(formatters)\n","        for fmt, turn in zip(formatters, turns):\n","            fmt(turn)\n","        return self\n","\n","\n","# Agent Definitions\n","import re\n","\n","\n","@contextlib.contextmanager\n","def _set_default_tensor_type(dtype: torch.dtype):\n","    \"\"\"\n","    Context Manager\n","        setting the default torch dtype to the given dtype during this context\n","    \"\"\"\n","    torch.set_default_dtype(dtype)\n","    yield\n","    torch.set_default_dtype(torch.float)\n","\n","\n","class GemmaAgent:\n","    def __init__(self, variant='7b-it-quant', device='cuda:0', system_prompt=None, few_shot_examples=None):\n","        self._variant = variant\n","        self._device = torch.device(device)\n","        self.formatter = GemmaFormatter(system_prompt=system_prompt, few_shot_examples=few_shot_examples)\n","\n","        # load the configuration of model\n","        print(\"Initializing model\")\n","        model_config = get_config_for_2b() if \"2b\" in variant else get_config_for_7b()\n","        model_config.tokenizer = os.path.join(WEIGHTS_PATH, \"tokenizer.model\")\n","        model_config.quant = \"quant\" in variant\n","\n","\n","        # load the model\n","        with _set_default_tensor_type(model_config.get_dtype()):\n","            model = GemmaForCausalLM(model_config)\n","            ckpt_path = os.path.join(WEIGHTS_PATH , f'gemma-{variant}.ckpt')\n","            model.load_weights(ckpt_path)\n","            self.model = model.to(self._device).eval()\n","\n","    def __call__(self, obs, *args):\n","        '''\n","        *important function\n","            this function is called when the agent is called in agent_fn() function, which means what happen all start from here\n","        '''\n","        self._start_session(obs)\n","        # format the prompt\n","        prompt = str(self.formatter)    # here it will call the __repr__ function of the formatter\n","        # call the LLM to get response\n","        response = self._call_llm(prompt)\n","        response = self._parse_response(response, obs)\n","        print(f\"{response=}\")\n","        return response\n","\n","    def _start_session(self, obs: dict):\n","        '''\n","            bascially rewrited in questioner and answerer agents\n","        '''\n","        raise NotImplementedError\n","\n","    def _call_llm(self, prompt, max_new_tokens=32, **sampler_kwargs):\n","        if sampler_kwargs is None:\n","            sampler_kwargs = {\n","                'temperature': 0.01,\n","                'top_p': 0.1,\n","                'top_k': 1,\n","        }\n","        response = self.model.generate(\n","            prompt,\n","            device=self._device,\n","            output_len=max_new_tokens,\n","            **sampler_kwargs,\n","        )\n","        return response\n","\n","    def _parse_keyword(self, response: str):\n","        '''\n","            Parse the keyword from the response.\n","        '''\n","        match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response)\n","        if match is None:\n","            keyword = ''\n","        else:\n","            keyword = match.group().lower()\n","        return keyword\n","\n","    def _parse_response(self, response: str, obs: dict):\n","        '''\n","            Parse the response from the model.\n","        '''\n","        raise NotImplementedError\n","\n","\n","def interleave_unequal(x, y):\n","    '''\n","        Interleave two lists of unequal length.\n","    '''\n","    return [\n","        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n","    ]\n","\n","\n","class GemmaQuestionerAgent(GemmaAgent):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","\n","    def _start_session(self, obs):\n","        '''\n","            could be a good example of how to start a session and apply the prompt and etc.\n","        '''\n","        self.formatter.reset()\n","        self.formatter.user(\"Let's play 20 Questions. You are playing the role of the Questioner.\")\n","        turns = interleave_unequal(obs.questions, obs.answers)\n","        self.formatter.apply_turns(turns, start_agent='model')\n","        if obs.turnType == 'ask':\n","            self.formatter.user(\"Please ask a yes-or-no question.\")\n","        elif obs.turnType == 'guess':\n","            self.formatter.user(\"Now guess the keyword. Surround your guess with double asterisks.\")\n","        self.formatter.start_model_turn()\n","\n","    def _parse_response(self, response: str, obs: dict):\n","        if obs.turnType == 'ask':\n","            match = re.search(\".+?\\?\", response.replace('*', ''))\n","            if match is None:\n","                question = \"Is it a person?\"\n","            else:\n","                question = match.group()\n","            return question\n","        elif obs.turnType == 'guess':\n","            guess = self._parse_keyword(response)\n","            return guess\n","        else:\n","            raise ValueError(\"Unknown turn type:\", obs.turnType)\n","\n","\n","class GemmaAnswererAgent(GemmaAgent):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","\n","    def _start_session(self, obs):\n","        self.formatter.reset()\n","        self.formatter.user(f\"Let's play 20 Questions. You are playing the role of the Answerer. The keyword is {obs.keyword} in the category {obs.category}.\")\n","        turns = interleave_unequal(obs.questions, obs.answers)\n","        self.formatter.apply_turns(turns, start_agent='user')\n","        self.formatter.user(f\"The question is about the keyword {obs.keyword} in the category {obs.category}. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.\")\n","        self.formatter.start_model_turn()\n","\n","    def _parse_response(self, response: str, obs: dict):\n","        answer = self._parse_keyword(response)\n","        return 'yes' if 'yes' in answer else 'no'\n","\n","\n","# Agent Creation\n","system_prompt = \"You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.\"\n","\n","few_shot_examples = [\n","    \"Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.\",\n","    \"Is it a person?\", \"**no**\",\n","    \"Is is a place?\", \"**yes**\",\n","    \"Is it a country?\", \"**yes** Now guess the keyword.\",\n","    \"**France**\", \"Correct!\",\n","]\n","\n","\n","# **IMPORTANT:** Define agent as a global so you only have to load\n","# the agent you need. Loading both will likely lead to OOM.\n","agent = None\n","\n","\n","def get_agent(name: str):\n","    global agent\n","    \n","    if agent is None and name == 'questioner':\n","        agent = GemmaQuestionerAgent(\n","            device='cuda:0',\n","            system_prompt=system_prompt,\n","            few_shot_examples=few_shot_examples,\n","        )\n","    elif agent is None and name == 'answerer':\n","        agent = GemmaAnswererAgent(\n","            device='cuda:0',\n","            system_prompt=system_prompt,\n","            few_shot_examples=few_shot_examples,\n","        )\n","    assert agent is not None, \"Agent not initialized.\"\n","\n","    return agent\n","\n","\n","def agent_fn(obs, cfg):\n","    if obs.turnType == \"ask\":\n","        response = get_agent('questioner')(obs)\n","    elif obs.turnType == \"guess\":\n","        response = get_agent('questioner')(obs)\n","    elif obs.turnType == \"answer\":\n","        response = get_agent('answerer')(obs)\n","    if response is None or len(response) <= 1:\n","        return \"yes\"\n","    else:\n","        return response"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":5.560311,"end_time":"2024-04-17T13:47:54.892856","exception":false,"start_time":"2024-04-17T13:47:49.332545","status":"completed"},"tags":[]},"outputs":[],"source":["!apt install pigz pv > /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":148.240766,"end_time":"2024-04-17T13:50:23.136669","exception":false,"start_time":"2024-04-17T13:47:54.895903","status":"completed"},"tags":[]},"outputs":[],"source":["# zip the submission with pigz and pv, where -C means change to the directory before adding the files\n","!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/pytorch/7b-it-quant/2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Prompt Formatting\n","import itertools\n","from typing import Iterable\n","\n","\n","class GemmaFormatter:\n","    '''\n","        A formatter for the Gemma model that allows for easy construction of prompts,\n","        basically use __repr__ function and other functions to format the prompt\n","\n","        containing following members:\n","            self._system_prompt: str\n","            self._few_shot_examples: Iterable\n","            self._turn_user: str\n","            self._turn_model: str\n","            self._state: str\n","            self._start_token: str\n","            self._end_token: str\n","            self.user: function\n","            self.model: function\n","    '''\n","\n","    \n","    _start_token = '<start_of_turn>'\n","    _end_token = '<end_of_turn>'\n","\n","    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n","        self._system_prompt = system_prompt\n","        self._few_shot_examples = few_shot_examples\n","        self._turn_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n","        self._turn_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n","        self.reset()\n","\n","    def __repr__(self):\n","        '''\n","            repr funcion is used to return the string representation of the object\n","            here we retrun the state of the object\n","        '''\n","        return self._state\n","\n","    def user(self, prompt):\n","        '''\n","\n","        '''\n","        self._state += self._turn_user.format(prompt)\n","        return self\n","\n","    def model(self, prompt):\n","        self._state += self._turn_model.format(prompt)\n","        return self\n","\n","    def start_user_turn(self):\n","        self._state += f\"{self._start_token}user\\n\"\n","        return self\n","\n","    def start_model_turn(self):\n","        self._state += f\"{self._start_token}model\\n\"\n","        return self\n","\n","    def end_turn(self):\n","        self._state += f\"{self._end_token}\\n\"\n","        return self\n","\n","    def reset(self):\n","        '''\n","            in this function self._state is reset to empty string and will be modified by user() and model() functions\n","        '''\n","        self._state = \"\"\n","        if self._system_prompt is not None:\n","            self.user(self._system_prompt)\n","        if self._few_shot_examples is not None:\n","            self.apply_turns(self._few_shot_examples, start_agent='user')\n","        return self\n","\n","\n","    def apply_turns(self, turns: Iterable, start_agent: str):\n","        '''\n","        Apply a sequence of turns to the formatter, starting with the specified agent.\n","        '''\n","        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model] # here, self.model and self.user are functions definded above\n","        formatters = itertools.cycle(formatters)\n","        for fmt, turn in zip(formatters, turns):\n","            fmt(turn)\n","        return self\n","\n","\n","system_prompt = \"You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.\"\n","\n","few_shot_examples = [\n","    \"Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.\",\n","    \"Is it a person?\", \"**no**\",\n","    \"Is is a place?\", \"**yes**\",\n","    \"Is it a country?\", \"**yes** Now guess the keyword.\",\n","    \"**France**\", \"Correct!\",\n","]\n","\n","formatter = GemmaFormatter(system_prompt=system_prompt, few_shot_examples=few_shot_examples)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","def interleave_unequal(x, y):\n","    '''\n","        Interleave two lists of unequal length.\n","    '''\n","    return [\n","        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n","    ]\n"]},{"cell_type":"markdown","metadata":{},"source":["#### How to use formatter\n","\n","basically what formatter has done are just \n","1. Adding existing Q&A\n","2. Putting the user prompt to the last user round \n","3. Adding the starting token for model. \n","4. Then everything will be sent to the model to generate following sentence"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<== [self.reset()] ==> \n"," <start_of_turn>user\n","You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.<end_of_turn>\n","<start_of_turn>model\n","Is it a person?<end_of_turn>\n","<start_of_turn>user\n","**no**<end_of_turn>\n","<start_of_turn>model\n","Is is a place?<end_of_turn>\n","<start_of_turn>user\n","**yes**<end_of_turn>\n","<start_of_turn>model\n","Is it a country?<end_of_turn>\n","<start_of_turn>user\n","**yes** Now guess the keyword.<end_of_turn>\n","<start_of_turn>model\n","**France**<end_of_turn>\n","<start_of_turn>user\n","Correct!<end_of_turn>\n"," \n","\n","<== [self.user(user_sys_prompt)] ==> \n"," <start_of_turn>user\n","You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.<end_of_turn>\n","<start_of_turn>model\n","Is it a person?<end_of_turn>\n","<start_of_turn>user\n","**no**<end_of_turn>\n","<start_of_turn>model\n","Is is a place?<end_of_turn>\n","<start_of_turn>user\n","**yes**<end_of_turn>\n","<start_of_turn>model\n","Is it a country?<end_of_turn>\n","<start_of_turn>user\n","**yes** Now guess the keyword.<end_of_turn>\n","<start_of_turn>model\n","**France**<end_of_turn>\n","<start_of_turn>user\n","Correct!<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Answerer. The keyword is dump_keyword in the category dump_cate.<end_of_turn>\n"," \n","\n","<== [interleave_unequal(x, y)] ==> \n"," ['Q_1', 'A_1', 'Q_2', 'A_2', 'Q_3', 'A_3', 'A_4'] \n","\n","<== [self.apply_turns( turns, \"user\")] ==> \n"," <start_of_turn>user\n","You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.<end_of_turn>\n","<start_of_turn>model\n","Is it a person?<end_of_turn>\n","<start_of_turn>user\n","**no**<end_of_turn>\n","<start_of_turn>model\n","Is is a place?<end_of_turn>\n","<start_of_turn>user\n","**yes**<end_of_turn>\n","<start_of_turn>model\n","Is it a country?<end_of_turn>\n","<start_of_turn>user\n","**yes** Now guess the keyword.<end_of_turn>\n","<start_of_turn>model\n","**France**<end_of_turn>\n","<start_of_turn>user\n","Correct!<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Answerer. The keyword is dump_keyword in the category dump_cate.<end_of_turn>\n","<start_of_turn>user\n","Q_1<end_of_turn>\n","<start_of_turn>model\n","A_1<end_of_turn>\n","<start_of_turn>user\n","Q_2<end_of_turn>\n","<start_of_turn>model\n","A_2<end_of_turn>\n","<start_of_turn>user\n","Q_3<end_of_turn>\n","<start_of_turn>model\n","A_3<end_of_turn>\n","<start_of_turn>user\n","A_4<end_of_turn>\n"," \n","\n","<== [self.user(user_sys_prompt)] ==> \n"," <start_of_turn>user\n","You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.<end_of_turn>\n","<start_of_turn>model\n","Is it a person?<end_of_turn>\n","<start_of_turn>user\n","**no**<end_of_turn>\n","<start_of_turn>model\n","Is is a place?<end_of_turn>\n","<start_of_turn>user\n","**yes**<end_of_turn>\n","<start_of_turn>model\n","Is it a country?<end_of_turn>\n","<start_of_turn>user\n","**yes** Now guess the keyword.<end_of_turn>\n","<start_of_turn>model\n","**France**<end_of_turn>\n","<start_of_turn>user\n","Correct!<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Answerer. The keyword is dump_keyword in the category dump_cate.<end_of_turn>\n","<start_of_turn>user\n","Q_1<end_of_turn>\n","<start_of_turn>model\n","A_1<end_of_turn>\n","<start_of_turn>user\n","Q_2<end_of_turn>\n","<start_of_turn>model\n","A_2<end_of_turn>\n","<start_of_turn>user\n","Q_3<end_of_turn>\n","<start_of_turn>model\n","A_3<end_of_turn>\n","<start_of_turn>user\n","A_4<end_of_turn>\n","<start_of_turn>user\n","The question is about the keyword dump_keyword in the category dump_cate. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.<end_of_turn>\n"," \n","\n","<== [self.start_model_turn()] ==> \n"," <start_of_turn>user\n","You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.<end_of_turn>\n","<start_of_turn>model\n","Is it a person?<end_of_turn>\n","<start_of_turn>user\n","**no**<end_of_turn>\n","<start_of_turn>model\n","Is is a place?<end_of_turn>\n","<start_of_turn>user\n","**yes**<end_of_turn>\n","<start_of_turn>model\n","Is it a country?<end_of_turn>\n","<start_of_turn>user\n","**yes** Now guess the keyword.<end_of_turn>\n","<start_of_turn>model\n","**France**<end_of_turn>\n","<start_of_turn>user\n","Correct!<end_of_turn>\n","<start_of_turn>user\n","Let's play 20 Questions. You are playing the role of the Answerer. The keyword is dump_keyword in the category dump_cate.<end_of_turn>\n","<start_of_turn>user\n","Q_1<end_of_turn>\n","<start_of_turn>model\n","A_1<end_of_turn>\n","<start_of_turn>user\n","Q_2<end_of_turn>\n","<start_of_turn>model\n","A_2<end_of_turn>\n","<start_of_turn>user\n","Q_3<end_of_turn>\n","<start_of_turn>model\n","A_3<end_of_turn>\n","<start_of_turn>user\n","A_4<end_of_turn>\n","<start_of_turn>user\n","The question is about the keyword dump_keyword in the category dump_cate. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.<end_of_turn>\n","<start_of_turn>model\n"," \n","\n"]}],"source":["formatter.reset()\n","print('<== [self.reset()] ==> \\n', str(formatter), '\\n')\n","formatter.user(f\"Let's play 20 Questions. You are playing the role of the Answerer. The keyword is {'dump_keyword'} in the category {'dump_cate'}.\")\n","print('<== [self.user(user_sys_prompt)] ==> \\n', str(formatter), '\\n')\n","turns = interleave_unequal(['Q_1', 'Q_2', 'Q_3'], ['A_1', 'A_2', 'A_3', 'A_4'])\n","print('<== [interleave_unequal(x, y)] ==> \\n', turns, '\\n')\n","formatter.apply_turns(turns, start_agent='user')\n","print('<== [self.apply_turns( turns, \"user\")] ==> \\n', str(formatter), '\\n')\n","formatter.user(f\"The question is about the keyword {'dump_keyword'} in the category {'dump_cate'}. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.\")\n","print('<== [self.user(user_sys_prompt)] ==> \\n', str(formatter), '\\n')\n","formatter.start_model_turn()\n","print('<== [self.start_model_turn()] ==> \\n', str(formatter), '\\n')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8550470,"sourceId":61247,"sourceType":"competition"},{"modelInstanceId":8749,"sourceId":11359,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"papermill":{"default_parameters":{},"duration":169.923583,"end_time":"2024-04-17T13:50:23.369773","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-17T13:47:33.44619","version":"2.5.0"}},"nbformat":4,"nbformat_minor":4}
