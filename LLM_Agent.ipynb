{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tttequila/Kaggle_20Q/blob/main/LLM_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqjWHE8-MQVl"
      },
      "source": [
        "Configuring your kaggle token, see more details in the [**Configure your API key**](https://ai.google.dev/gemma/docs/setup) section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndGYpeKSFV5U",
        "outputId": "84bb69d3-e2d6-414c-bca5-f8589978fece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nNrgspAf9T8W"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir ~/.kaggle\n",
        "# change the first path to your path of kaggle.json\n",
        "cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-l45FATYz0T",
        "outputId": "3418fd87-0721-4a26-c3ca-617516d878fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 779.1/779.1 MB 1.4 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 40.2 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.1/168.1 MB 6.9 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.3/21.3 MB 73.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install -q -U torch immutabledict sentencepiece\n",
        "\n",
        "# pip install -q -U kerasnlp\n",
        "# pip install -q -U keras>=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hM-hIzsF9VI"
      },
      "source": [
        "### Loading mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOKNU1dkGLVR",
        "outputId": "1e3a8dbb-ff13-407f-c049-552c7b36e08d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'gemma_pytorch'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 222 (delta 90), reused 87 (delta 55), pack-reused 68\u001b[K\n",
            "Receiving objects: 100% (222/222), 2.19 MiB | 15.98 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ]
        }
      ],
      "source": [
        "# %%bash\n",
        "!git clone https://github.com/google/gemma_pytorch.git\n",
        "\n",
        "# !mkdir /kaggle/working/gemma/\n",
        "# !mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "bba625c15982460e98611f8edbdaa565",
            "ae11770fb0ce446bbcf16c4ff3a23ec6",
            "eae207bb982e48b4b7d16973ab46866c",
            "5f83051bc9ca40d3b5f1f1a66f1e95c1",
            "0f7960a68e12442ebf4e560d1206f268",
            "0a412d2972f340b49ad07708fc95e8f0",
            "baed24fddd77489ebe9d5d1f7ac9f8c7",
            "f3eae9c63d1545b786d49525d43deef9",
            "52f425bb48984e01acee327c0de2c6b3",
            "1c49d383eb5a45a99f87d5814a3a2ae3",
            "78354105a73c48a6942a19416ed861e9",
            "61e3c070558e4bde80ba13ebc6dd64ae",
            "0f0521043eae4862938eb1ccfb160dfa",
            "612928d980594c66aa52f38d6037d4e5",
            "85a7112f258748938453b9f66379a229",
            "6de1853e4d924c3d887c3fedbfa7d184",
            "df33256681e1416bb90d761086e6f02a"
          ]
        },
        "id": "HhC3bL88SqDk",
        "outputId": "a279eccd-bae8-4714-a561-9db2ca16b3d9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bba625c15982460e98611f8edbdaa565",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# login the kaggle (need to store you kaggle.json to your google dirve)\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F70B5D8GKLSJ",
        "outputId": "4f1c02f0-f4d6-4ec0-f49c-ca5c9af08da3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Attaching model 'google/gemma/pyTorch/7b-it-quant' to your Colab notebook...\n"
          ]
        }
      ],
      "source": [
        "# Choose variant and machine type\n",
        "VARIANT = '7b-it-quant'\n",
        "MACHINE_TYPE = 'cuda'\n",
        "\n",
        "import os\n",
        "\n",
        "# Load model weights\n",
        "weights_dir = kagglehub.model_download(f'google/gemma/pyTorch/{VARIANT}')\n",
        "\n",
        "# Ensure that the tokenizer is present\n",
        "tokenizer_path = os.path.join(weights_dir, 'tokenizer.model')\n",
        "assert os.path.isfile(tokenizer_path), 'Tokenizer not found!'\n",
        "# Ensure that the checkpoint is present\n",
        "ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n",
        "assert os.path.isfile(ckpt_path), 'PyTorch checkpoint not found!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZwV2hWxLgsB"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# sys.path.append(\"/content/gemma_pytorch/gemma\")\n",
        "# print(sys.path)\n",
        "# from gemma.config import get_config_for_7b, get_config_for_2b\n",
        "# from gemma.model import GemmaForCausalLM, GemmaModel\n",
        "# import contextlib, torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL142KfsLg_y",
        "outputId": "132a1509-7d23-4fbf-bffd-ff7bb7376805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython', 'gemma_pytorch/gemma', 'gemma_pytorch']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"gemma_pytorch/gemma\")\n",
        "sys.path.append(\"gemma_pytorch\")\n",
        "print(sys.path)\n",
        "from gemma.config import get_config_for_7b, get_config_for_2b\n",
        "from gemma.model import GemmaForCausalLM, GemmaModel\n",
        "import contextlib, torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_2fiRlXXGBHQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "@contextlib.contextmanager\n",
        "def _set_default_tensor_type(dtype: torch.dtype):\n",
        "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
        "  torch.set_default_dtype(dtype)\n",
        "  yield\n",
        "  torch.set_default_dtype(torch.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1Aq-hydOOVX"
      },
      "source": [
        "## Loading model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y10m95XaBeQ-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gemma\n",
        "\n",
        "# Set up model config.\n",
        "model_config = get_config_for_7b()\n",
        "model_config.tokenizer = tokenizer_path\n",
        "model_config.quant = 'quant' in VARIANT\n",
        "# model_config.architecture = gemma.config.Architecture.GEMMA_2\n",
        "\n",
        "with _set_default_tensor_type(model_config.get_dtype()):\n",
        "  device = torch.device(MACHINE_TYPE)\n",
        "  model = GemmaForCausalLM(model_config)\n",
        "  model.load_weights(ckpt_path)\n",
        "  model = model.to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM7KjtKR8GxW"
      },
      "source": [
        "## Play with Gemma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbSO_x4kR_2Y"
      },
      "source": [
        "### format your prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpnczT4kR7pZ"
      },
      "outputs": [],
      "source": [
        "# Chat templates\n",
        "USER_CHAT_TEMPLATE = '<start_of_turn>user\\n{prompt}<end_of_turn>\\n'\n",
        "MODEL_CHAT_TEMPLATE = '<start_of_turn>model\\n{prompt}<end_of_turn>\\n'\n",
        "\n",
        "prompt = (\n",
        "    USER_CHAT_TEMPLATE.format(\n",
        "        prompt='What is a good place for travel in the US?'\n",
        "    )\n",
        ")\n",
        "print('Chat prompt:\\n', prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqh86PQqSLTY"
      },
      "source": [
        "### Chat & Response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB6VrHQ8__6W"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDSPbiluSQwt",
        "outputId": "1c6efae1-8668-4519-873a-e0411c747bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[response in 40.20s]\n",
            "The best place to travel in the US depends on your interests and preferences. Here are a few popular destinations:\n",
            "\n",
            "**For city lovers:**\n",
            "\n",
            "* **New York, NY:** A vibrant and historical city with a diverse culture.\n",
            "* **Los Angeles, CA:** A beautiful and glamorous city with a variety of neighborhoods to explore.\n",
            "* **Chicago, IL:** A friendly city with a rich history and iconic architecture.\n",
            "* **San Francisco, CA:** A historic city with a stunning Golden\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# generate with formatted prompts\n",
        "start = time.time()\n",
        "response_1 = model.generate(\n",
        "    USER_CHAT_TEMPLATE.format(prompt=prompt),\n",
        "    device=device,\n",
        "    output_len=100,\n",
        ")\n",
        "print(f\"[response in {(time.time()-start):.2f}s]\\n{response_1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9loBFRC0TQab",
        "outputId": "4f3e3ff0-26e5-4812-f41d-863c378b218e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'time' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-290360541df1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# or directly talk to Gemma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m response_2 = model.generate(\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'Write a poem about an llm writing a poem.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ],
      "source": [
        "# or directly talk to Gemma\n",
        "start = time.time()\n",
        "response_2 = model.generate(\n",
        "    'Write a poem about an llm writing a poem.',\n",
        "    device=device,\n",
        "    output_len=2000,\n",
        ")\n",
        "print(f\"[response in {(time.time()-start):.2f}s]\\n{response_2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QElPuSuVxomJ"
      },
      "source": [
        "### applying formatter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_Bnh_pjVGBA"
      },
      "source": [
        "### documents\n",
        "\n",
        "<details>\n",
        "  <summary> model </summary>\n",
        "  \n",
        "  - `self.forward()`: getting next token and corresponding logits\n",
        "  - `self.generate()`: see summary below. May need to be rewriten if we wanna get the cumulative logits for the whole sentence  \n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary> model.generate() </summary>\n",
        "  \n",
        "  - **prompts** | `Union[str, Sequence[str]]`: Your prompts\n",
        "  - **device** | `Any`: Devices\n",
        "  - **output_len** | `int`: max output length\n",
        "  - **temperature** | `Union[float, None]`: temperature degree, controlling how variant its response could be  \n",
        "  - **top_p** | `float`:\n",
        "  - **top_k** | `int`:\n",
        "\n",
        "  regarding temperature, top_p and top_k, check this [link](https://blog.csdn.net/REfusing/article/details/137866583)\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz3oLOTJxnPc",
        "outputId": "5c8ce674-18f7-4eef-abb1-6437b3c86bad"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from typing import Iterable\n",
        "from typing import Any, List, Optional, Sequence, Tuple, Union\n",
        "\n",
        "def interleave_unequal(x, y):\n",
        "    '''\n",
        "        Interleave two lists of unequal length.\n",
        "    '''\n",
        "    return [\n",
        "        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n",
        "    ]\n",
        "\n",
        "class Formatter:\n",
        "    \n",
        "    '''\n",
        "        formatter class to format the prompt text for the model. \n",
        "        A general idea is \n",
        "    '''\n",
        "    \n",
        "    _start_token = '<start_of_turn>'\n",
        "    _end_token = '<end_of_turn>'\n",
        "        \n",
        "    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n",
        "        self._system_prompt = system_prompt\n",
        "        self._few_shot_examples = few_shot_examples\n",
        "        self._template_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n",
        "        self._template_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n",
        "        self._all_prompt = ''\n",
        "        self.reset()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self._all_prompt\n",
        "        \n",
        "    def reset(self):\n",
        "        # if system prompt is provided, add it to the prompt\n",
        "        if self._system_prompt:\n",
        "            self._all_prompt += self._template_user.format(self._system_prompt)\n",
        "        # same for few shot examples\n",
        "        if self._few_shot_examples:\n",
        "            self.add_existing_rounds(self._few_shot_examples, start_agent='user')\n",
        "        \n",
        "    def add_user_round(self, user_prompt: str):\n",
        "        # add user round to the prompt\n",
        "        self._all_prompt += self._template_user.format(user_prompt)\n",
        "\n",
        "    def add_agent_round(self, model_response: str):\n",
        "        self._all_prompt += self._template_model.format(model_response)\n",
        "    \n",
        "    # def add_few_shot_examples(self):\n",
        "    #     raise NotImplementedError\n",
        "    \n",
        "    # def add_system_prompt(self):\n",
        "    #     raise NotImplementedError\n",
        "    \n",
        "    def add_existing_rounds(self, rounds: Iterable, start_agent: str):\n",
        "        '''\n",
        "            Apply a sequence of rounds to the formatter, starting with the specified agent.\n",
        "        '''\n",
        "        formatters = [self.add_agent_round, self.add_user_round] if start_agent == 'model' else [self.add_user_round, self.add_agent_round] # here, self.model and self.user are functions definded above\n",
        "        formatters = itertools.cycle(formatters)\n",
        "        for fmt, round in zip(formatters, rounds):\n",
        "            fmt(round)\n",
        "        return self\n",
        "    \n",
        "    def add_new_round(self):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    def formate_MCQA(self):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def add_start_token(self):\n",
        "        raise NotImplementedError\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start_of_turn>user\n",
            "You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Is it a person?<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Is is a place?<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Is it a country?<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes** Now guess the keyword.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**France**<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Correct!<end_of_turn>\n",
            "\n",
            "\n",
            "<start_of_turn>user\n",
            "You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Is it a person?<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Is is a place?<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Is it a country?<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes** Now guess the keyword.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**France**<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Correct!<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Q1<end_of_turn>\n",
            "<start_of_turn>model\n",
            "A1<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Q2<end_of_turn>\n",
            "<start_of_turn>model\n",
            "A2<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Q3<end_of_turn>\n",
            "<start_of_turn>model\n",
            "A3<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Q4<end_of_turn>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_gemma = lambda x: \"A4\"\n",
        "\n",
        "rounds = ['Q1', 'A1', 'Q2', 'A2', 'Q3', 'A3', 'Q4']\n",
        "\n",
        "system_prompt = \"You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.\"\n",
        "\n",
        "few_shot_examples = [\n",
        "    \"Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.\",\n",
        "    \"Is it a person?\", \"**no**\",\n",
        "    \"Is is a place?\", \"**yes**\",\n",
        "    \"Is it a country?\", \"**yes** Now guess the keyword.\",\n",
        "    \"**France**\", \"Correct!\",\n",
        "]\n",
        "\n",
        "dummy_formatter = Formatter(system_prompt=system_prompt, few_shot_examples=few_shot_examples)\n",
        "\n",
        "print(str(dummy_formatter), end='\\n\\n')\n",
        "\n",
        "print(str(dummy_formatter.add_existing_rounds(rounds, start_agent='user')))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNYMmzQ5FvJCWOwpRNhb8xe",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a412d2972f340b49ad07708fc95e8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de1853e4d924c3d887c3fedbfa7d184",
            "placeholder": "​",
            "style": "IPY_MODEL_df33256681e1416bb90d761086e6f02a",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "0f0521043eae4862938eb1ccfb160dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f7960a68e12442ebf4e560d1206f268": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_612928d980594c66aa52f38d6037d4e5",
            "style": "IPY_MODEL_85a7112f258748938453b9f66379a229",
            "tooltip": ""
          }
        },
        "1c49d383eb5a45a99f87d5814a3a2ae3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f425bb48984e01acee327c0de2c6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f83051bc9ca40d3b5f1f1a66f1e95c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_61e3c070558e4bde80ba13ebc6dd64ae",
            "placeholder": "​",
            "style": "IPY_MODEL_0f0521043eae4862938eb1ccfb160dfa",
            "value": ""
          }
        },
        "612928d980594c66aa52f38d6037d4e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e3c070558e4bde80ba13ebc6dd64ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de1853e4d924c3d887c3fedbfa7d184": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78354105a73c48a6942a19416ed861e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a7112f258748938453b9f66379a229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ae11770fb0ce446bbcf16c4ff3a23ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3eae9c63d1545b786d49525d43deef9",
            "placeholder": "​",
            "style": "IPY_MODEL_52f425bb48984e01acee327c0de2c6b3",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "baed24fddd77489ebe9d5d1f7ac9f8c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "bba625c15982460e98611f8edbdaa565": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae11770fb0ce446bbcf16c4ff3a23ec6",
              "IPY_MODEL_eae207bb982e48b4b7d16973ab46866c",
              "IPY_MODEL_5f83051bc9ca40d3b5f1f1a66f1e95c1",
              "IPY_MODEL_0f7960a68e12442ebf4e560d1206f268",
              "IPY_MODEL_0a412d2972f340b49ad07708fc95e8f0"
            ],
            "layout": "IPY_MODEL_baed24fddd77489ebe9d5d1f7ac9f8c7"
          }
        },
        "df33256681e1416bb90d761086e6f02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eae207bb982e48b4b7d16973ab46866c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1c49d383eb5a45a99f87d5814a3a2ae3",
            "placeholder": "​",
            "style": "IPY_MODEL_78354105a73c48a6942a19416ed861e9",
            "value": ""
          }
        },
        "f3eae9c63d1545b786d49525d43deef9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
