{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tttequila/Kaggle_20Q/blob/main/7B_MultiCoT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqjWHE8-MQVl"
      },
      "source": [
        "Configuring your kaggle token, see more details in the [**Configure your API key**](https://ai.google.dev/gemma/docs/setup) section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENaMz5-35Ayi"
      },
      "source": [
        "### set up env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndGYpeKSFV5U",
        "outputId": "f81213fd-7b12-495b-d871-33d817485257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nNrgspAf9T8W",
        "outputId": "43421299-1cfe-41d3-9beb-08f8a27580a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "mkdir ~/.kaggle\n",
        "# change the first path to your path of kaggle.json\n",
        "cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o-l45FATYz0T"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install -q -U torch immutabledict sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google/gemma_pytorch.git"
      ],
      "metadata": {
        "id": "1EUA6-EY6DCH",
        "outputId": "c51f05ec-f098-4918-c2e8-0fbc51d4777d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gemma_pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lbfq9Ee5Ayo"
      },
      "source": [
        "### set up Gemma lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "d28b9f2a28784963b0836139efce029e",
            "552f984db9b24abe8cf8a0b3c3be352c",
            "99fbe19d07084443aa86dff3d8c51627",
            "28c6239810a4408180aafd4dcab8d1f8",
            "83bc3ecc29fa4e48a437f4ea09a2e980",
            "e4d7988597994de9923c4d077edec3b0",
            "77e4fd7cdd8644c0aa8d30c16dd2bfab",
            "73a4d667296649b49da969884254ed3e",
            "20fd618bfa0849f3b4dc2fecaa0ece26",
            "18e220fb73444e3fb24cd96aa5338739",
            "ded686d1611e4312ad50dfef307eddb3",
            "1aea595b3286428d82a02efefe46396d",
            "6090da6caf5248498689cfb417dea2cc",
            "32daa8692b164e2dbcf9d94ab2f30836",
            "36ca273ab85b474380223beedaf4df18",
            "3f53b13cbf8c40eab468ade15bb8c53c",
            "888a104f44114e3991dfd37fcbdaa6f2"
          ]
        },
        "id": "HhC3bL88SqDk",
        "outputId": "c9c96607-bb84-4ec2-e328-8cefe42bb95e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d28b9f2a28784963b0836139efce029e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# login the kaggle (need to store you kaggle.json to your google dirve)\n",
        "import kagglehub\n",
        "kagglehub.login()\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"gemma_pytorch/gemma\")\n",
        "sys.path.append(\"gemma_pytorch\")\n",
        "import contextlib, torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gemma.config import get_config_for_7b, get_config_for_2b\n",
        "from gemma.model import GemmaForCausalLM, GemmaModel"
      ],
      "metadata": {
        "id": "vmThtLaQ8nwA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y10m95XaBeQ-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gemma\n",
        "import itertools\n",
        "from typing import Iterable\n",
        "from typing import Any, List, Optional, Sequence, Tuple, Union\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bURsXpMG5Ayu"
      },
      "outputs": [],
      "source": [
        "@contextlib.contextmanager\n",
        "def _set_default_tensor_type(dtype: torch.dtype):\n",
        "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
        "  torch.set_default_dtype(dtype)\n",
        "  yield\n",
        "  torch.set_default_dtype(torch.float)\n",
        "\n",
        "\n",
        "def interleave_unequal(x, y):\n",
        "    '''\n",
        "        Interleave two lists of unequal length.\n",
        "    '''\n",
        "    return [\n",
        "        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLOddhGA5Ayv"
      },
      "source": [
        "### Building Agents\n",
        "\n",
        "<details>\n",
        "  <summary> model </summary>\n",
        "  \n",
        "  - `self.forward()`: getting next token and corresponding logits\n",
        "  - `self.generate()`: see summary below. May need to be rewriten if we wanna get the cumulative logits for the whole sentence  \n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary> model.generate() </summary>\n",
        "  \n",
        "  - **prompts** | `Union[str, Sequence[str]]`: Your prompts\n",
        "  - **device** | `Any`: Devices\n",
        "  - **output_len** | `int`: max output length\n",
        "  - **temperature** | `Union[float, None]`: temperature degree, controlling how variant its response could be  \n",
        "  - **top_p** | `float`:\n",
        "  - **top_k** | `int`:\n",
        "\n",
        "  regarding temperature, top_p and top_k, check this [link](https://blog.csdn.net/REfusing/article/details/137866583)\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL_iy3Ai5Ayw"
      },
      "source": [
        "#### Define Formatter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AtsqJUJs5Ayw",
        "outputId": "8b36182d-b47d-4867-c2d0-fcc6a1d7f953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start_of_turn>user\n",
            "You are a highly knowledgeable naturalist with extensive knowledge about objects, places, and people around the world, almost like a search engine. You also possess strong reasoning abilities, allowing you to deduce the answer to your query using existing knowledge and information. You need to utilize your knowledge and reasoning skills to play a game of 20 questions. In each round of the game, choose the binary attribute most likely to aid your deduction, such as \"a cross on the flag.\" Using this attribute, ask a question in English. Generally, the most helpful attribute provides the maximum information gain, meaning it significantly reduces the entropy of your guess, regardless of whether the answer is **yes** or **no**. For example, if you believe asking about the color is most helpful for your deduction, you should ask, \"Is it a thing with a red color?\" And after your thorough thinking, you need to wrap some key point with double stars and their corresponding content with double quotation marks (such as **key point**: \"corresponding content\").  Here are few examples of how to use Chain of thought:<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Now give me an example of thinking with the Chain of Thought<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given Information: [\"is a country\", \"is in Europe\", \"its flag is with red color\"] Considerations: 1. Geographical Location: European countries can be divided into regions such as Northern Europe, Southern Europe, Western Europe, and Eastern Europe. This division can effectively narrow down the options. 2. Population and Area: Considering population and area can also eliminate some countries. 3. Other Colors on the Flag: We know the flag has red; we can further narrow down by asking about other colors. 4. Language: European countries have various languages; asking about the official language can narrow it further. Reasoning: Southern Europe includes a few countries such as Spain, Italy, Portugal, Greece, etc. Determining if it is in Southern Europe can immediately eliminate about three-quarters of European countries. Compared to questions about flag colors or language, geographical location questions are more evenly distributed, and a yes or no answer will significantly narrow down the range. Possible Next Steps: If the answer is yes, we can further inquire about other notable characteristics of these countries, such as language or history. If the answer is no, we can turn our attention to Western, Eastern, or Northern Europe and continue narrowing down the options.**Key Attribute** \"in Southern Europe\"**Question** \"Is this country in Southern Europe?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Now let us play a game of 20 questions. You will be the questioner, and I will be the answerer.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "It is the first round, so i will randomly choose a attribute from [\"country\", \"city\", \"landmark\"] as the first attribut. Here I choose country as the first attribute.**Key Attribute** \"a country\"**Question** \"Is it a country?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\"] Considerations: 1. Type of Entity: Determining whether it is a city or a landmark can greatly narrow down our options. 2. Geographical Location: If we can determine the continent, we can significantly reduce the number of possible cities or landmarks. 3. Cultural/Historical Significance: Asking about cultural or historical significance can also be helpful, but it might be too broad at this stage. Reasoning: To effectively narrow it down, the most efficient next step is to determine if it is a city or a landmark. By determining if it is a city, we can immediately focus on known cities globally, which are fewer and more well-documented compared to all possible landmarks. If it is not a city, we can then focus on landmarks, which might require more specific questions but will also significantly narrow our scope. Possible Next Steps: If the answer is yes, we can then ask about the continent or specific features of the city. If the answer is no, we can ask about the type of landmark or its location. **Key Attribute** \"a city**Question** \"Is it a city?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\"] Considerations: Alright, so it is not a city. Now we know it must be a landmark. Given this, our goal is to identify the type or location of the landmark. 1. Type of Landmark: There are various types such as natural landmarks (mountains, rivers), man-made landmarks (statues, buildings), or historical sites. 2. Geographical Location: Identifying the continent or region can greatly narrow down the possibilities. To get a high information gain, let us narrow down the type of landmark first. Reasoning: Landmarks can be broadly categorized into man-made or natural. This binary distinction will help us immediately focus on a more specific set of possibilities. Man-made landmarks include famous buildings, statues, monuments, etc., while natural landmarks include mountains, rivers, and natural formations. Possible Next Steps: If the answer is yes, we can then ask about the purpose or era of the man-made structure. If the answer is no, we can focus on identifying the type of natural landmark or its location. **Key Attribute** \"a man-made landmark\"**Question** \"Is it a man-made landmark?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is not a man-made landmark\"] Considerations: 1. Type of Natural Landmark: Common natural landmarks include mountains, rivers, lakes, forests, deserts, etc. 2. Geographical Location: Identifying the continent or region can still be very helpful. To further narrow down, let us focus on the type of natural landmark. Reasoning: River are one of the most well-known types of natural landmarks. Possible Next Steps: If the answer is yes, we can then focus on identifying which river by asking about its specific features or location. If the answer is no, we can eliminate a significant category and focus on other types of natural landmarks like mountains, lakes, deserts, or forests. **Key Attribute** \"a river\"**Question** \"Is it a river?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\"] Considerations: Great, so it is a river. Now, we need to narrow down which river it could be. To do this effectively, identifying the continent or region will significantly help. 1. Geographical Location: Identifying the continent or region can narrow down the list of possible rivers considerably. 2. Length or Size: Asking about whether it is among the longest rivers might also help. 3. Famous Rivers: There are some rivers that are globally well-known due to their significance. To achieve a high information gain, let us focus on the geographical location. Reasoning: Asia has some of the world us most significant and longest rivers, such as the Yangtze, Ganges, and Mekong. Possible Next Steps: If the answer is yes, we can focus on Asian rivers specifically. If the answer is no, we can eliminate Asia and consider other continents like Africa, Europe, South America, or North America. **Key Attribute** \"located in Asia\"**Question** \"Is this reiver located in Asia?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\"] Excellent, the river is located in Asia. This narrows down our options significantly. Now, we need to focus on identifying which river it could be. Considerations: 1. Famous Asian Rivers: Asia has several famous rivers, such as the Yangtze, Ganges, Mekong, Indus, and Yellow River. 2. Geographical Features: We could ask about the river's length, the countries it flows through, or any significant historical or cultural associations. 3. To narrow it down further, let us focus on whether it is one of the most well-known rivers. Reasoning: These three rivers are among the longest and most significant in Asia. Possible Next Steps: If the answer is yes, we can focus on distinguishing between these three. If the answer is no, we can focus on other significant rivers like the Ganges, Indus, or Brahmaputra. **Key Attribute** \"one of the three longest rivers in Asia\"**Question** \"Is this river one of the three longest rivers in Asia (Yangtze, Yellow, or Mekong)?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\"] Great, we now know it is one of the three longest rivers in Asia: the Yangtze, Yellow, or Mekong. Let us narrow it down further by focusing on specific characteristics of these rivers. Considerations: 1. Geographical Location: We can ask about the countries the river flows through. 2. Cultural/Historical Significance: Each of these rivers has distinct cultural and historical significance. To narrow it down further, let us ask about the country. Reasoning: Both the Yangtze and Yellow rivers flow through China, while the Mekong flows through several countries including China, but predominantly in Southeast Asia. Possible Next Steps: If the answer is yes, it will most likely be the Yangtze or Yellow River. If the answer is no, it must be the Mekong River. **Key Attribute** \"flow through China\"**Question** \"Does this river flow through China?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\", \"It flows through China\"] Great, so the river flows through China. This means it is either the Yangtze River or the Yellow River. To determine which one it is, we should focus on distinguishing features. Considerations: 1. Length: The Yangtze is the longest river in Asia and the third-longest in the world. 2. Color/Name: The Yellow River is named for its yellowish color due to loess sediments. Reasoning: The Yangtze River is the longest river in Asia. Possible Next Steps: If the answer is yes, it is the Yangtze River. If the answer is no, it must be the Yellow River. **Key Attribute** \"the longest river in Asia\"**Question** \"Is this river the longest river in Asia?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**, Now guess the keyword. Give your analysis with chain of thought and known information. And surround your guess with double asterisks (*) in the end, such as **Guess** \"your guess\"<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\", \"It flows through China\", \"It is the longest river in Asia\"] Given the information provided, let us analyze and guess the keyword step by step: It is not a country: This eliminates any possibility of a country being the answer. It is either a landmark or a city: This narrows the options to two categories. It is not a landmark: This further narrows the options, confirming that the answer must be a city.It is a river: This information conflicts with the previous determination that it is a city unless miscommunication exists. Assuming this is accurate, we will consider this entity as a river instead of a city. It is located in Asia: This geographic specification helps limit the river to one continent. It is one of the three longest rivers in Asia: This is a critical clue that significantly narrows the options to three major rivers: the Yangtze, the Yellow River, and the Mekong. Since the provided information describes it as one of the three longest rivers in Asia, and we have confirmed it must be a river, not a city or landmark, we can focus on these three rivers. Final Step: Given the specified criteria, the keyword you are referring to could be either the Yangtze, Yellow River, or Mekong. However, you mentioned it is specifically a river and not a landmark or city, which leads directly to these rivers. For a direct guess based on the longest rivers in Asia, we could guess the Yangtze River since it is the longest river in Asia and fits all the criteria provided. Conclusion: The keyword is likely \"Yangtze River\", considering it is one of the longest and fits the location and other descriptions provided. **Guess**: \"Yangtze River\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Correct!<end_of_turn>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterable\n",
        "import itertools\n",
        "\n",
        "class PromptFormatter:\n",
        "\n",
        "    '''\n",
        "        formatter class to format the prompt text for the model.\n",
        "        A general idea is\n",
        "    '''\n",
        "\n",
        "    _start_token = '<start_of_turn>'\n",
        "    _end_token = '<end_of_turn>'\n",
        "\n",
        "    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n",
        "        self._system_prompt = system_prompt\n",
        "        self._few_shot_examples = few_shot_examples\n",
        "        self._template_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n",
        "        self._template_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n",
        "        self._all_prompt = ''\n",
        "        self.reset()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self._all_prompt\n",
        "\n",
        "    def reset(self):\n",
        "        self._all_prompt = ''\n",
        "        # if system prompt is provided, add it to the prompt\n",
        "        if self._system_prompt:\n",
        "            self._all_prompt += self._template_user.format(self._system_prompt)\n",
        "        # same for few shot examples\n",
        "        if self._few_shot_examples:\n",
        "            self.add_rounds(self._few_shot_examples, start_agent='user')\n",
        "\n",
        "    def add_user_round(self, user_prompt: str):\n",
        "        # add user round to the prompt\n",
        "        self._all_prompt += self._template_user.format(user_prompt)\n",
        "\n",
        "    def add_agent_round(self, model_response: str):\n",
        "        self._all_prompt += self._template_model.format(model_response)\n",
        "\n",
        "    def add_rounds(self, rounds: Iterable, start_agent: str):\n",
        "        '''\n",
        "            Apply a sequence of rounds to the formatter, starting with the specified agent.\n",
        "        '''\n",
        "        formatters = [self.add_agent_round, self.add_user_round] if start_agent == 'model' else [self.add_user_round, self.add_agent_round] # here, self.model and self.user are functions definded above\n",
        "        formatters = itertools.cycle(formatters)\n",
        "        for fmt, round in zip(formatters, rounds):\n",
        "            fmt(round)\n",
        "        return self\n",
        "\n",
        "    # def add_end_token(self):\n",
        "    #     self._all_prompt += f\"{self._end_token}\\n\"\n",
        "\n",
        "    def add_new_round(self, player: str, prompt:str = None, end_token: bool = False):\n",
        "        self._all_prompt += f\"{self._start_token}{player}\\n\"\n",
        "        if prompt:\n",
        "            self._all_prompt += f'{prompt}'\n",
        "        if end_token:\n",
        "            # self.add_end_token()\n",
        "            self._all_prompt += f\"{self._end_token}\\n\"\n",
        "\n",
        "    def formate_MCQA(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "sys_prompt = 'You are a highly knowledgeable naturalist with extensive knowledge about objects, places, and people around the world, almost like a search engine. You also possess strong reasoning abilities, allowing you to deduce the answer to your query using existing knowledge and information. \\\n",
        "You need to utilize your knowledge and reasoning skills to play a game of 20 questions. \\\n",
        "In each round of the game, choose the binary attribute most likely to aid your deduction, such as \"a cross on the flag.\" \\\n",
        "Using this attribute, ask a question in English. Generally, the most helpful attribute provides the maximum information gain, meaning it significantly reduces the entropy of your guess, regardless of whether the answer is **yes** or **no**. For example, if you believe asking about the color is most helpful for your deduction, you should ask, \"Is it a thing with a red color?\" \\\n",
        "And after your thorough thinking, you need to wrap some key point with double stars and their corresponding content with double quotation marks (such as **key point**: \"corresponding content\").  Here are few examples of how to use Chain of thought:'\n",
        "\n",
        "few_shot_examples = [\n",
        "\n",
        "'Now give me an example of thinking with the Chain of Thought',\n",
        "\n",
        "# 'Given Information: [\"is a country\", \"is in Europe\", \"its flag is with red color\"] \\\n",
        "# Considerations: \\\n",
        "# 1. Geographical Location: European countries can be divided into regions such as Northern Europe, Southern Europe, Western Europe, and Eastern Europe. This division can effectively narrow down the options. \\\n",
        "# 2. Population and Area: Considering population and area can also eliminate some countries. \\\n",
        "# 3. Other Colors on the Flag: We know the flag has red; we can further narrow down by asking about other colors. \\\n",
        "# 4. Language: European countries have various languages; asking about the official language can narrow it further. \\\n",
        "# Reasoning: Southern Europe includes a few countries such as Spain, Italy, Portugal, Greece, etc. Determining if it is in Southern Europe can immediately eliminate about three-quarters of European countries. \\\n",
        "# Compared to questions about flag colors or language, geographical location questions are more evenly distributed, and a yes or no answer will significantly narrow down the range. \\\n",
        "# Possible Next Steps: \\\n",
        "# If the answer is yes, we can further inquire about other notable characteristics of these countries, such as language or history. \\\n",
        "# If the answer is no, we can turn our attention to Western, Eastern, or Northern Europe and continue narrowing down the options.\\\n",
        "# **Key Attribute** \"in Southern Europe\"\\\n",
        "# **Question** \"Is this country in Southern Europe?\"',\n",
        "\n",
        "# 'Now let us play a game of 20 questions. You will be the questioner, and I will be the answerer.',\n",
        "\n",
        "# 'It is the first round, so i will randomly choose a attribute from [\"country\", \"city\", \"landmark\"] as the first attribut. Here I choose country as the first attribute.\\\n",
        "# **Key Attribute** \"a country\"\\\n",
        "# **Question** \"Is it a country?\"',\n",
        "\n",
        "# '**no**',\n",
        "\n",
        "# 'Given information: [\"It is not a country\", \"It is either a landmark or a city\"] \\\n",
        "# Considerations: \\\n",
        "# 1. Type of Entity: Determining whether it is a city or a landmark can greatly narrow down our options. \\\n",
        "# 2. Geographical Location: If we can determine the continent, we can significantly reduce the number of possible cities or landmarks. \\\n",
        "# 3. Cultural/Historical Significance: Asking about cultural or historical significance can also be helpful, but it might be too broad at this stage. \\\n",
        "# Reasoning: To effectively narrow it down, the most efficient next step is to determine if it is a city or a landmark. By determining if it is a city, we can immediately focus on known cities globally, which are fewer and more well-documented compared to all possible landmarks. \\\n",
        "# If it is not a city, we can then focus on landmarks, which might require more specific questions but will also significantly narrow our scope. \\\n",
        "# Possible Next Steps: \\\n",
        "# If the answer is yes, we can then ask about the continent or specific features of the city. \\\n",
        "# If the answer is no, we can ask about the type of landmark or its location. \\\n",
        "# **Key Attribute** \"a city\\\n",
        "# **Question** \"Is it a city?\"',\n",
        "\n",
        "# '**no**',\n",
        "\n",
        "# 'Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\"] \\\n",
        "# Considerations: \\\n",
        "# Alright, so it is not a city. Now we know it must be a landmark. Given this, our goal is to identify the type or location of the landmark. \\\n",
        "# 1. Type of Landmark: There are various types such as natural landmarks (mountains, rivers), man-made landmarks (statues, buildings), or historical sites. \\\n",
        "# 2. Geographical Location: Identifying the continent or region can greatly narrow down the possibilities. \\\n",
        "# To get a high information gain, let us narrow down the type of landmark first. \\\n",
        "# Reasoning: Landmarks can be broadly categorized into man-made or natural. This binary distinction will help us immediately focus on a more specific set of possibilities. \\\n",
        "# Man-made landmarks include famous buildings, statues, monuments, etc., while natural landmarks include mountains, rivers, and natural formations. \\\n",
        "# Possible Next Steps: \\\n",
        "# If the answer is yes, we can then ask about the purpose or era of the man-made structure. \\\n",
        "# If the answer is no, we can focus on identifying the type of natural landmark or its location. \\\n",
        "# **Key Attribute** \"a man-made landmark\"\\\n",
        "# **Question** \"Is it a man-made landmark?\"',\n",
        "\n",
        "# '**no**',\n",
        "\n",
        "'Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is not a man-made landmark\"] \\\n",
        "Considerations: \\\n",
        "1. Type of Natural Landmark: Common natural landmarks include mountains, rivers, lakes, forests, deserts, etc. \\\n",
        "2. Geographical Location: Identifying the continent or region can still be very helpful. \\\n",
        "To further narrow down, let us focus on the type of natural landmark. \\\n",
        "Reasoning: River are one of the most well-known types of natural landmarks. \\\n",
        "Possible Next Steps: \\\n",
        "If the answer is yes, we can then focus on identifying which river by asking about its specific features or location. \\\n",
        "If the answer is no, we can eliminate a significant category and focus on other types of natural landmarks like mountains, lakes, deserts, or forests. \\\n",
        "**Key Attribute** \"a river\"\\\n",
        "**Question** \"Is it a river?\"',\n",
        "\n",
        "'**yes**',\n",
        "\n",
        "'Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\"] \\\n",
        "Considerations: \\\n",
        "Great, so it is a river. Now, we need to narrow down which river it could be. To do this effectively, identifying the continent or region will significantly help. \\\n",
        "1. Geographical Location: Identifying the continent or region can narrow down the list of possible rivers considerably. \\\n",
        "2. Length or Size: Asking about whether it is among the longest rivers might also help. \\\n",
        "3. Famous Rivers: There are some rivers that are globally well-known due to their significance. \\\n",
        "To achieve a high information gain, let us focus on the geographical location. \\\n",
        "Reasoning: Asia has some of the world us most significant and longest rivers, such as the Yangtze, Ganges, and Mekong. \\\n",
        "Possible Next Steps: \\\n",
        "If the answer is yes, we can focus on Asian rivers specifically. \\\n",
        "If the answer is no, we can eliminate Asia and consider other continents like Africa, Europe, South America, or North America. \\\n",
        "**Key Attribute** \"located in Asia\"\\\n",
        "**Question** \"Is this reiver located in Asia?\"',\n",
        "\n",
        "'**yes**',\n",
        "\n",
        "'Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\"] \\\n",
        "Excellent, the river is located in Asia. This narrows down our options significantly. Now, we need to focus on identifying which river it could be. \\\n",
        "Considerations: \\\n",
        "1. Famous Asian Rivers: Asia has several famous rivers, such as the Yangtze, Ganges, Mekong, Indus, and Yellow River. \\\n",
        "2. Geographical Features: We could ask about the river\\'s length, the countries it flows through, or any significant historical or cultural associations. \\\n",
        "3. To narrow it down further, let us focus on whether it is one of the most well-known rivers. \\\n",
        "Reasoning: These three rivers are among the longest and most significant in Asia. \\\n",
        "Possible Next Steps: \\\n",
        "If the answer is yes, we can focus on distinguishing between these three. \\\n",
        "If the answer is no, we can focus on other significant rivers like the Ganges, Indus, or Brahmaputra. \\\n",
        "**Key Attribute** \"one of the three longest rivers in Asia\"\\\n",
        "**Question** \"Is this river one of the three longest rivers in Asia (Yangtze, Yellow, or Mekong)?\"',\n",
        "\n",
        "'**yes**',\n",
        "\n",
        "'Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\"] \\\n",
        "Great, we now know it is one of the three longest rivers in Asia: the Yangtze, Yellow, or Mekong. Let us narrow it down further by focusing on specific characteristics of these rivers. \\\n",
        "Considerations: \\\n",
        "1. Geographical Location: We can ask about the countries the river flows through. \\\n",
        "2. Cultural/Historical Significance: Each of these rivers has distinct cultural and historical significance. \\\n",
        "To narrow it down further, let us ask about the country. \\\n",
        "Reasoning: Both the Yangtze and Yellow rivers flow through China, while the Mekong flows through several countries including China, but predominantly in Southeast Asia. \\\n",
        "Possible Next Steps: \\\n",
        "If the answer is yes, it will most likely be the Yangtze or Yellow River. \\\n",
        "If the answer is no, it must be the Mekong River. \\\n",
        "**Key Attribute** \"flow through China\"\\\n",
        "**Question** \"Does this river flow through China?\"',\n",
        "\n",
        "'**yes**',\n",
        "\n",
        "'Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\", \"It flows through China\"] \\\n",
        "Great, so the river flows through China. This means it is either the Yangtze River or the Yellow River. To determine which one it is, we should focus on distinguishing features. \\\n",
        "Considerations: \\\n",
        "1. Length: The Yangtze is the longest river in Asia and the third-longest in the world. \\\n",
        "2. Color/Name: The Yellow River is named for its yellowish color due to loess sediments. \\\n",
        "Reasoning: The Yangtze River is the longest river in Asia. \\\n",
        "Possible Next Steps: \\\n",
        "If the answer is yes, it is the Yangtze River. \\\n",
        "If the answer is no, it must be the Yellow River. \\\n",
        "**Key Attribute** \"the longest river in Asia\"\\\n",
        "**Question** \"Is this river the longest river in Asia?\"',\n",
        "\n",
        "'**yes**, Now guess the keyword. Give your analysis with chain of thought and known information. And surround your guess with double asterisks (*) in the end, such as **Guess** \"your guess\"',\n",
        "\n",
        "'Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\", \"It flows through China\", \"It is the longest river in Asia\"] \\\n",
        "Given the information provided, let us analyze and guess the keyword step by step: \\\n",
        "It is not a country: This eliminates any possibility of a country being the answer. \\\n",
        "It is either a landmark or a city: This narrows the options to two categories. \\\n",
        "It is not a landmark: This further narrows the options, confirming that the answer must be a city.\\\n",
        "It is a river: This information conflicts with the previous determination that it is a city unless miscommunication exists. Assuming this is accurate, we will consider this entity as a river instead of a city. \\\n",
        "It is located in Asia: This geographic specification helps limit the river to one continent. \\\n",
        "It is one of the three longest rivers in Asia: This is a critical clue that significantly narrows the options to three major rivers: the Yangtze, the Yellow River, and the Mekong. \\\n",
        "Since the provided information describes it as one of the three longest rivers in Asia, and we have confirmed it must be a river, not a city or landmark, we can focus on these three rivers. \\\n",
        "Final Step: \\\n",
        "Given the specified criteria, the keyword you are referring to could be either the Yangtze, Yellow River, or Mekong. However, you mentioned it is specifically a river and not a landmark or city, which leads directly to these rivers. \\\n",
        "For a direct guess based on the longest rivers in Asia, we could guess the Yangtze River since it is the longest river in Asia and fits all the criteria provided. \\\n",
        "Conclusion: The keyword is likely \"Yangtze River\", considering it is one of the longest and fits the location and other descriptions provided. \\\n",
        "**Guess**: \"Yangtze River\"',\n",
        "\n",
        "'Correct!']\n",
        "\n",
        "print(str(PromptFormatter(sys_prompt, few_shot_examples)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5NRQGRB5Ayz"
      },
      "source": [
        "#### Define Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hIPcPhjD5Ay0"
      },
      "outputs": [],
      "source": [
        "from ast import parse\n",
        "import random\n",
        "\n",
        "class GemmaAgent_Guesser:\n",
        "\n",
        "    def __init__(self, model_variant, device='cuda:0', env=\"kaggle\", output_len=200, system_prompt=None, few_shot_examples=None):\n",
        "        # model initialization\n",
        "        self.device = device\n",
        "        self.model_variant = model_variant\n",
        "\n",
        "        WEIGHTS_PATH = self._set_up_env(env)\n",
        "\n",
        "        # Ensure that the tokenizer is present\n",
        "        tokenizer_path = os.path.join(WEIGHTS_PATH, 'tokenizer.model')\n",
        "        assert os.path.isfile(tokenizer_path), 'Tokenizer not found!'\n",
        "\n",
        "        # Ensure that the checkpoint is present\n",
        "        ckpt_path = os.path.join(WEIGHTS_PATH , f'gemma-{model_variant}.ckpt')\n",
        "        assert os.path.isfile(ckpt_path), 'PyTorch checkpoint not found!'\n",
        "\n",
        "        # loading model configuration\n",
        "        model_config = get_config_for_2b() if \"2b\" in model_variant else get_config_for_7b()\n",
        "        model_config.quant = \"quant\" in model_variant\n",
        "        model_config.tokenizer = os.path.join(WEIGHTS_PATH, \"tokenizer.model\")\n",
        "\n",
        "        with _set_default_tensor_type(model_config.get_dtype()):\n",
        "            self.model = GemmaForCausalLM(model_config)\n",
        "            self.model.load_weights(ckpt_path)\n",
        "            self.model = self.model.to(self.device).eval()\n",
        "\n",
        "        # agent args\n",
        "        self.formatter = PromptFormatter(system_prompt=system_prompt,\n",
        "                                         few_shot_examples=few_shot_examples)\n",
        "        self.round_num = 0\n",
        "        self.known_info = []\n",
        "        self.last_key_attribute = None\n",
        "        self.last_guess = None\n",
        "        self.output_len = output_len\n",
        "\n",
        "    def _set_up_env(self, env):\n",
        "\n",
        "        if env == 'kaggle':\n",
        "            print(\"Loading model in Kaggle, model weights will be searched within local directories.\")\n",
        "\n",
        "            # kaggle configuration\n",
        "            KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
        "            if os.path.exists(KAGGLE_AGENT_PATH):\n",
        "                WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, f\"gemma/pytorch/{self.model_variant}/2\")\n",
        "            else:\n",
        "                WEIGHTS_PATH = f\"/kaggle/input/gemma/pytorch/{self.model_variant}/2\"\n",
        "\n",
        "        elif env == 'colab':\n",
        "            print(\"Loading model in Colab, starting from downloading the model weights.\")\n",
        "\n",
        "            WEIGHTS_PATH = kagglehub.model_download(f'google/gemma/pyTorch/{self.model_variant}')\n",
        "        else:\n",
        "            raise ValueError(\"Argument 'env' should be in ['kaggle', 'colab']\")\n",
        "\n",
        "        return WEIGHTS_PATH\n",
        "\n",
        "    def _parse_response(self, response : str):\n",
        "        '''\n",
        "            parse the response into a dictionary.\n",
        "            may contain three keys: key_attribute, question, guess and their value respectively.\n",
        "            e.g.: {\"key_attribute\": 'a country', \"question\": 'Is it a country?'} for a parsed asker response.\n",
        "        '''\n",
        "        pattern = re.compile(r'\\*\\*([^*]+)\\*\\*[^*\"]+\"([^\"]+)\"')\n",
        "        matches = pattern.findall(response.lower())\n",
        "        parse_dict = {'key attribute':None, 'question':None, 'guess':None}\n",
        "        for k, v in matches:\n",
        "          if 'attr' in k:\n",
        "            parse_dict['key attribute'] = v\n",
        "          elif 'ques' in k:\n",
        "            parse_dict['question'] = v\n",
        "          elif 'guess' in k:\n",
        "            parse_dict['guess'] = v\n",
        "\n",
        "        return parse_dict\n",
        "\n",
        "    def _format_prompt(self, obs):\n",
        "        # reset formatter\n",
        "        self.formatter.reset()\n",
        "        self.formatter.add_new_round('user', 'Remember how to use CoT as above, now let us play a new game from the begining.', True)\n",
        "        # add played rounds\n",
        "        rounds = interleave_unequal(obs[\"questions\"], obs[\"answers\"])\n",
        "        self.formatter.add_rounds(rounds, start_agent='user')\n",
        "        if obs[\"turnType\"] == 'ask':\n",
        "            self.formatter.add_new_round('user',\n",
        "                                         'Now it is your turn to ask a question. Please using chain of thought to construct a new question based on what you have known and your knowledge storage. Do not forget to indicate key attribute, question with double asterisk (**?**) and their content with double quotation markers (\"?\") when it is needed, such as **Key Attribute** \"your attribute\" and **Question** \"your question\"',\n",
        "                                         True)\n",
        "        elif obs[\"turnType\"] == 'guess':\n",
        "            self.formatter.add_new_round('user',\n",
        "                                         'Now guess the keyword. Give your analysis with chain of thought and known information. And surround a pointer of guess with double asterisks (**?**) and your guessed keyword with doublr quotation markers (\"?\") in the end, such as **Guess** \"your guess\"',\n",
        "                                         True)\n",
        "        # start of model response\n",
        "        self.formatter.add_new_round('model', f'Given information: {str(self.known_info)}', False)\n",
        "\n",
        "    def __call__(self, obs, cfg=None):\n",
        "        '''\n",
        "            Main function to interact with the model.\n",
        "                1. update known information based on the observation and round number\n",
        "                2. format the prompt with the observation\n",
        "                3. generate response from the model\n",
        "                4. parse the response and update information if needed\n",
        "        '''\n",
        "        print(f\"=========== round: {self.round_num} ===========\")\n",
        "        self.round_num += 1\n",
        "        # Update known information\n",
        "        if self.round_num - 1 == 0:\n",
        "            # for the first round, randomly choose an attribute as initialization\n",
        "            initial_categories = ['person', 'thing', 'place']\n",
        "            self.last_key_attribute = random.choice(initial_categories)\n",
        "            self.else_categories = list(set(initial_categories) - set([self.last_key_attribute]))\n",
        "            response = f'Is it a {self.last_key_attribute}?'\n",
        "            round\n",
        "            return response\n",
        "        elif self.round_num - 1 == 1:\n",
        "            # if it is the second round, grab the answer and update known information\n",
        "            last_answer = obs[\"answers\"][-1]\n",
        "            if last_answer == 'yes':\n",
        "                self.known_info.append(f'a {self.last_key_attribute}')\n",
        "            else:\n",
        "                self.known_info.append(f'not a {self.last_key_attribute}')\n",
        "                self.known_info.append(f'either a {self.else_categories[0]} or a {self.else_categories[1]}')\n",
        "        else:\n",
        "            # other rounds, update known information\n",
        "            last_answer = obs['answers'][-1]\n",
        "            if last_answer == 'yes':\n",
        "                self.known_info.append(f'is {self.last_key_attribute}')\n",
        "            else:\n",
        "                self.known_info.append(f'is not {self.last_key_attribute}')\n",
        "\n",
        "        # # Update guessed keywords\n",
        "        # self.known_info.append(f'keyword is not {self.last_guess}')\n",
        "        # self.known_info = list(set(self.known_info))\n",
        "\n",
        "        print(f\"\\nkey attribute: {self.last_key_attribute}, guess: {self.last_guess}\")\n",
        "\n",
        "        # Formatting prompt with observations\n",
        "        self._format_prompt(obs)\n",
        "        prompt = str(self.formatter)\n",
        "        print(f\"\\nPrompt: {prompt}\")\n",
        "        # Getting response from LLM\n",
        "        response = self.model.generate(prompt, device=self.device, output_len=self.output_len)\n",
        "        print(f'\\nTurn Type: {obs[\"turnType\"]}\\nResponse: {response}')\n",
        "\n",
        "        # parse response and update information if needed\n",
        "        parse_dict = self._parse_response(response)\n",
        "        print(f'\\nParse_dict: {parse_dict}')\n",
        "\n",
        "        # if in an ask turn, try to grab the key attribute from the response and update last key attribute for the next information updating\n",
        "        if obs[\"turnType\"] == 'ask':\n",
        "            # successfully grab the key attribute from the response\n",
        "            if parse_dict['key attribute']:\n",
        "                self.last_key_attribute = parse_dict['key attribute']\n",
        "            # no key attribute parsed from the response, directly use question as key attribute\n",
        "            elif parse_dict['question']:\n",
        "                self.last_key_attribute  = parse_dict['question']\n",
        "                ret = parse_dict['question']\n",
        "                return ret\n",
        "            # worst case, there is neither key attribute nor question parsed from the response, randomly choose an attribute\n",
        "            else:\n",
        "                random_alphabet = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
        "                ret = f'is it started with alphabet {random_alphabet}?'\n",
        "                self.last_key_attribute = f'started with alphabet {random_alphabet}'\n",
        "                return ret\n",
        "\n",
        "            # parsed response has question, use question as response\n",
        "            if parse_dict['question']:\n",
        "                ret = parse_dict['question']\n",
        "            # parsed response has no question but have key attribute, use key attribute as question\n",
        "            else:\n",
        "\n",
        "                ret = f'is it {self.last_key_attribute}?'\n",
        "        # if in a guess turn, try to grab the guess from the response and update last guess for the next information updating\n",
        "        elif obs[\"turnType\"] == 'guess':\n",
        "            if parse_dict['guess']:\n",
        "                self.last_guess = parse_dict['guess']\n",
        "                ret = parse_dict['guess']\n",
        "            # if there is no guess parsed from the response, return empty string\n",
        "            else:\n",
        "                ret = ''\n",
        "        else:\n",
        "            raise ValueError('Invalid turnType.')\n",
        "\n",
        "        return ret\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Debug"
      ],
      "metadata": {
        "id": "KX1Zbm8X5IUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install kaggle_environments\n",
        "import kaggle_environments"
      ],
      "metadata": {
        "id": "z0D3B9ks51xa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy agent\n",
        "def simple_agent1(obs, cfg):\n",
        "    # if agent is guesser and turnType is \"ask\"\n",
        "    if obs['turnType'] == \"ask\": response = \"Is it a duck?\"\n",
        "    elif obs.turnType == \"guess\": response = \"duck\"\n",
        "    elif obs.turnType == \"answer\": response = \"no\"\n",
        "    return response\n",
        "\n",
        "def simple_agent2(obs, cfg):\n",
        "    # if agent is guesser and turnType is \"ask\"\n",
        "    if obs.turnType == \"ask\": response = \"Is it a bird?\"\n",
        "    elif obs.turnType == \"guess\": response = \"bird\"\n",
        "    elif obs.turnType == \"answer\": response = \"no\"\n",
        "    return response\n",
        "\n",
        "def simple_agent3(obs, cfg):\n",
        "    # if agent is guesser and turnType is \"ask\"\n",
        "    if obs.turnType == \"ask\": response = \"Is it a pig?\"\n",
        "    elif obs.turnType == \"guess\": response = \"pig\"\n",
        "    elif obs.turnType == \"answer\": response = \"no\"\n",
        "    return response\n",
        "\n",
        "def simple_agent4(obs, cfg):\n",
        "    # if agent is guesser and turnType is \"ask\"\n",
        "    if obs.turnType == \"ask\": response = \"Is it a cow?\"\n",
        "    elif obs.turnType == \"guess\": response = \"cow\"\n",
        "    elif obs.turnType == \"answer\": response = \"no\"\n",
        "    return response"
      ],
      "metadata": {
        "id": "r6ozTUpm5MUw",
        "outputId": "12f3af9e-b72f-4569-cb62-c5f63886f207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# **IMPORTANT:** Define agent as a global so you only have to load\n",
        "# the agent you need. Loading both will likely lead to OOM.\n",
        "# del agent\n",
        "agent = None\n",
        "print(agent)\n",
        "\n",
        "# def get_agent(name: str):\n",
        "#     global agent\n",
        "\n",
        "#     if agent is None and name == 'questioner':\n",
        "#         agent = GemmaAgent_Guesser(VARIANT, MACHINE_TYPE, 'colab',\n",
        "#                                    sys_prompt, few_shot_examples)\n",
        "#     elif agent is None and name == 'answerer':\n",
        "#         raise NotImplementedError\n",
        "#     assert agent is not None, \"Agent not initialized.\"\n",
        "\n",
        "#     return agent\n",
        "\n",
        "\n",
        "# def agent_fn(obs, cfg):\n",
        "#     if obs.turnType == \"ask\":\n",
        "#         response = get_agent('questioner')(obs)\n",
        "#     elif obs.turnType == \"guess\":\n",
        "#         response = get_agent('questioner')(obs)\n",
        "#     elif obs.turnType == \"answer\":\n",
        "#         response = get_agent('answerer')(obs)\n",
        "#     if response is None or len(response) <= 1:\n",
        "#         return \"yes\"\n",
        "#     else:\n",
        "#         return response\n"
      ],
      "metadata": {
        "id": "YqaOSuKrEo5h",
        "outputId": "bd5db85f-79d4-4849-f8f9-bf3c3958aa9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug_config = {'episodeSteps': 10,     # initial step plus 3 steps per round (ask/answer/guess)\n",
        "                'actTimeout': 5,       # agent time per round in seconds; default is 60\n",
        "                'runTimeout': 60,      # max time for the episode in seconds; default is 1200\n",
        "                'agentTimeout': 3600}  # obsolete field; default is 3600\n",
        "env = kaggle_environments.make(\"llm_20_questions\", debug_config, debug=True)\n",
        "print(f'the key word is: {kaggle_environments.envs.llm_20_questions.llm_20_questions.keyword}\\nwith alts as {kaggle_environments.envs.llm_20_questions.llm_20_questions.alts}')"
      ],
      "metadata": {
        "id": "_vJhIFse_rnX",
        "outputId": "43dfa169-4f0a-4504-e775-da557cc09ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the key word is: Oak table\n",
            "with alts as []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Choose variant and machine type\n",
        "VARIANT = '7b-it-quant'\n",
        "MACHINE_TYPE = 'cuda'\n",
        "agent = None\n"
      ],
      "metadata": {
        "id": "ti92oAf6CrEb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agent = GemmaAgent_Guesser(VARIANT, MACHINE_TYPE, 'colab', 150, sys_prompt, few_shot_examples)\n",
        "agent.formatter._sys_prompt = sys_prompt\n",
        "agent.formatter._few_shot_examples = few_shot_examples\n",
        "agent.round_num = 4\n",
        "agent.last_key_attribute = 'a person'\n",
        "agent.last_guess = 'pig'\n",
        "agent.known_info = ['not a place', 'either a person or a thing', 'not a thing']\n",
        "# print(str(agent.formatter))\n",
        "obs = {'remainingOverageTime': 300, 'questions': ['Is it a place?', 'Is it a thing?', 'Is it a person?'], 'guesses': ['pig', 'pig', 'pig'], 'answers': ['no', 'no', 'yes'], 'role': 'guesser', 'turnType': 'ask', 'keyword': '', 'category': ''}\n",
        "start = time.time()\n",
        "agent(obs)\n",
        "print(f\"TIME: {(time.time()-start):.4f}s\")"
      ],
      "metadata": {
        "id": "ygzpOabZM7ub",
        "outputId": "91bdee1e-6cee-43ab-84f5-dc108c5a07b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== round: 4 ===========\n",
            "\n",
            "key attribute: a person, guess: pig\n",
            "\n",
            "Prompt: <start_of_turn>user\n",
            "You are a highly knowledgeable naturalist with extensive knowledge about objects, places, and people around the world, almost like a search engine. You also possess strong reasoning abilities, allowing you to deduce the answer to your query using existing knowledge and information. You need to utilize your knowledge and reasoning skills to play a game of 20 questions. In each round of the game, choose the binary attribute most likely to aid your deduction, such as \"a cross on the flag.\" Using this attribute, ask a question in English. Generally, the most helpful attribute provides the maximum information gain, meaning it significantly reduces the entropy of your guess, regardless of whether the answer is **yes** or **no**. For example, if you believe asking about the color is most helpful for your deduction, you should ask, \"Is it a thing with a red color?\" And after your thorough thinking, you need to wrap some key point with double stars and their corresponding content with double quotation marks (such as **key point**: \"corresponding content\").  Here are few examples of how to use Chain of thought:<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Now give me an example of thinking with the Chain of Thought<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given Information: [\"is a country\", \"is in Europe\", \"its flag is with red color\"] Considerations: 1. Geographical Location: European countries can be divided into regions such as Northern Europe, Southern Europe, Western Europe, and Eastern Europe. This division can effectively narrow down the options. 2. Population and Area: Considering population and area can also eliminate some countries. 3. Other Colors on the Flag: We know the flag has red; we can further narrow down by asking about other colors. 4. Language: European countries have various languages; asking about the official language can narrow it further. Reasoning: Southern Europe includes a few countries such as Spain, Italy, Portugal, Greece, etc. Determining if it is in Southern Europe can immediately eliminate about three-quarters of European countries. Compared to questions about flag colors or language, geographical location questions are more evenly distributed, and a yes or no answer will significantly narrow down the range. Possible Next Steps: If the answer is yes, we can further inquire about other notable characteristics of these countries, such as language or history. If the answer is no, we can turn our attention to Western, Eastern, or Northern Europe and continue narrowing down the options.**Key Attribute** \"in Southern Europe\"**Question** \"Is this country in Southern Europe?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Now let us play a game of 20 questions. You will be the questioner, and I will be the answerer.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "It is the first round, so i will randomly choose a attribute from [\"country\", \"city\", \"landmark\"] as the first attribut. Here I choose country as the first attribute.**Key Attribute** \"a country\"**Question** \"Is it a country?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\"] Considerations: 1. Type of Entity: Determining whether it is a city or a landmark can greatly narrow down our options. 2. Geographical Location: If we can determine the continent, we can significantly reduce the number of possible cities or landmarks. 3. Cultural/Historical Significance: Asking about cultural or historical significance can also be helpful, but it might be too broad at this stage. Reasoning: To effectively narrow it down, the most efficient next step is to determine if it is a city or a landmark. By determining if it is a city, we can immediately focus on known cities globally, which are fewer and more well-documented compared to all possible landmarks. If it is not a city, we can then focus on landmarks, which might require more specific questions but will also significantly narrow our scope. Possible Next Steps: If the answer is yes, we can then ask about the continent or specific features of the city. If the answer is no, we can ask about the type of landmark or its location. **Key Attribute** \"a city**Question** \"Is it a city?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\"] Considerations: Alright, so it is not a city. Now we know it must be a landmark. Given this, our goal is to identify the type or location of the landmark. 1. Type of Landmark: There are various types such as natural landmarks (mountains, rivers), man-made landmarks (statues, buildings), or historical sites. 2. Geographical Location: Identifying the continent or region can greatly narrow down the possibilities. To get a high information gain, let us narrow down the type of landmark first. Reasoning: Landmarks can be broadly categorized into man-made or natural. This binary distinction will help us immediately focus on a more specific set of possibilities. Man-made landmarks include famous buildings, statues, monuments, etc., while natural landmarks include mountains, rivers, and natural formations. Possible Next Steps: If the answer is yes, we can then ask about the purpose or era of the man-made structure. If the answer is no, we can focus on identifying the type of natural landmark or its location. **Key Attribute** \"a man-made landmark\"**Question** \"Is it a man-made landmark?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**no**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is not a man-made landmark\"] Considerations: 1. Type of Natural Landmark: Common natural landmarks include mountains, rivers, lakes, forests, deserts, etc. 2. Geographical Location: Identifying the continent or region can still be very helpful. To further narrow down, let us focus on the type of natural landmark. Reasoning: River are one of the most well-known types of natural landmarks. Possible Next Steps: If the answer is yes, we can then focus on identifying which river by asking about its specific features or location. If the answer is no, we can eliminate a significant category and focus on other types of natural landmarks like mountains, lakes, deserts, or forests. **Key Attribute** \"a river\"**Question** \"Is it a river?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\"] Considerations: Great, so it is a river. Now, we need to narrow down which river it could be. To do this effectively, identifying the continent or region will significantly help. 1. Geographical Location: Identifying the continent or region can narrow down the list of possible rivers considerably. 2. Length or Size: Asking about whether it is among the longest rivers might also help. 3. Famous Rivers: There are some rivers that are globally well-known due to their significance. To achieve a high information gain, let us focus on the geographical location. Reasoning: Asia has some of the world us most significant and longest rivers, such as the Yangtze, Ganges, and Mekong. Possible Next Steps: If the answer is yes, we can focus on Asian rivers specifically. If the answer is no, we can eliminate Asia and consider other continents like Africa, Europe, South America, or North America. **Key Attribute** \"located in Asia\"**Question** \"Is this reiver located in Asia?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\"] Excellent, the river is located in Asia. This narrows down our options significantly. Now, we need to focus on identifying which river it could be. Considerations: 1. Famous Asian Rivers: Asia has several famous rivers, such as the Yangtze, Ganges, Mekong, Indus, and Yellow River. 2. Geographical Features: We could ask about the river's length, the countries it flows through, or any significant historical or cultural associations. 3. To narrow it down further, let us focus on whether it is one of the most well-known rivers. Reasoning: These three rivers are among the longest and most significant in Asia. Possible Next Steps: If the answer is yes, we can focus on distinguishing between these three. If the answer is no, we can focus on other significant rivers like the Ganges, Indus, or Brahmaputra. **Key Attribute** \"one of the three longest rivers in Asia\"**Question** \"Is this river one of the three longest rivers in Asia (Yangtze, Yellow, or Mekong)?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\"] Great, we now know it is one of the three longest rivers in Asia: the Yangtze, Yellow, or Mekong. Let us narrow it down further by focusing on specific characteristics of these rivers. Considerations: 1. Geographical Location: We can ask about the countries the river flows through. 2. Cultural/Historical Significance: Each of these rivers has distinct cultural and historical significance. To narrow it down further, let us ask about the country. Reasoning: Both the Yangtze and Yellow rivers flow through China, while the Mekong flows through several countries including China, but predominantly in Southeast Asia. Possible Next Steps: If the answer is yes, it will most likely be the Yangtze or Yellow River. If the answer is no, it must be the Mekong River. **Key Attribute** \"flow through China\"**Question** \"Does this river flow through China?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\", \"It flows through China\"] Great, so the river flows through China. This means it is either the Yangtze River or the Yellow River. To determine which one it is, we should focus on distinguishing features. Considerations: 1. Length: The Yangtze is the longest river in Asia and the third-longest in the world. 2. Color/Name: The Yellow River is named for its yellowish color due to loess sediments. Reasoning: The Yangtze River is the longest river in Asia. Possible Next Steps: If the answer is yes, it is the Yangtze River. If the answer is no, it must be the Yellow River. **Key Attribute** \"the longest river in Asia\"**Question** \"Is this river the longest river in Asia?\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "**yes**, Now guess the keyword. Give your analysis with chain of thought and known information. And surround your guess with double asterisks (*) in the end, such as **Guess** \"your guess\"<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: [\"It is not a country\", \"It is either a landmark or a city\", \"It is not a landmark\", \"It is a river\", \"It is located in Asia\", \"It is one of the three longest rivers in Asia\", \"It flows through China\", \"It is the longest river in Asia\"] Given the information provided, let us analyze and guess the keyword step by step: It is not a country: This eliminates any possibility of a country being the answer. It is either a landmark or a city: This narrows the options to two categories. It is not a landmark: This further narrows the options, confirming that the answer must be a city.It is a river: This information conflicts with the previous determination that it is a city unless miscommunication exists. Assuming this is accurate, we will consider this entity as a river instead of a city. It is located in Asia: This geographic specification helps limit the river to one continent. It is one of the three longest rivers in Asia: This is a critical clue that significantly narrows the options to three major rivers: the Yangtze, the Yellow River, and the Mekong. Since the provided information describes it as one of the three longest rivers in Asia, and we have confirmed it must be a river, not a city or landmark, we can focus on these three rivers. Final Step: Given the specified criteria, the keyword you are referring to could be either the Yangtze, Yellow River, or Mekong. However, you mentioned it is specifically a river and not a landmark or city, which leads directly to these rivers. For a direct guess based on the longest rivers in Asia, we could guess the Yangtze River since it is the longest river in Asia and fits all the criteria provided. Conclusion: The keyword is likely \"Yangtze River\", considering it is one of the longest and fits the location and other descriptions provided. **Guess**: \"Yangtze River\"<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Correct!<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Remember how to use CoT as above, now let us play a new game from the begining.<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Is it a place?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "no<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Is it a thing?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "no<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Is it a person?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "yes<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Now it is your turn to ask a question. Please using chain of thought to construct a new question based on what you have known and your knowledge storage. Do not forget to indicate key attribute, question with double asterisk (**?**) and their content with double quotation markers (\"?\") when it is needed, such as **Key Attribute** \"your attribute\" and **Question** \"your question\"<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Given information: ['not a place', 'either a person or a thing', 'not a thing', 'a a person']\n",
            "\n",
            "Turn Type: ask\n",
            "Response:  Considerations: 1. It is not a place: Since the answer is not a place, the remaining options include a person or a thing. 2. If it is a person: We could ask about their nationality or their field of expertise to narrow down the possibilities. 3. If it is a thing: We could ask about other distinctive characteristics of the thing to narrow down the options. Reasoning: Given the information available, the most efficient next step would be to see if the answer is\n",
            "\n",
            "Parse_dict: {'key attribute': None, 'question': None, 'guess': None}\n",
            "TIME: 57.7720s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "game_output = env.run(agents=[simple_agent1,simple_agent2, simple_agent3, simple_agent4])\n",
        "print(game_output[9])"
      ],
      "metadata": {
        "id": "atPfPu0bD0rU",
        "outputId": "60aa219e-f242-48ab-cfef-59c1ff6e9b07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'action': 'duck', 'reward': 0, 'info': {}, 'observation': {'remainingOverageTime': 300, 'step': 9, 'questions': ['Is it a duck?', 'Is it a duck?', 'Is it a duck?'], 'guesses': ['duck', 'duck', 'duck'], 'answers': ['no', 'no', 'no'], 'role': 'guesser', 'turnType': 'ask', 'keyword': '', 'category': ''}, 'status': 'DONE'}, {'action': '', 'reward': 0, 'info': {}, 'observation': {'remainingOverageTime': 300, 'questions': ['Is it a duck?', 'Is it a duck?', 'Is it a duck?'], 'guesses': ['duck', 'duck', 'duck'], 'answers': ['no', 'no', 'no'], 'role': 'answerer', 'turnType': 'answer', 'keyword': 'Oak table', 'category': 'things'}, 'status': 'DONE'}, {'action': 'pig', 'reward': 0, 'info': {}, 'observation': {'remainingOverageTime': 300, 'questions': ['Is it a pig?', 'Is it a pig?', 'Is it a pig?'], 'guesses': ['pig', 'pig', 'pig'], 'answers': ['no', 'no', 'no'], 'role': 'guesser', 'turnType': 'ask', 'keyword': '', 'category': ''}, 'status': 'DONE'}, {'action': '', 'reward': 0, 'info': {}, 'observation': {'remainingOverageTime': 300, 'questions': ['Is it a pig?', 'Is it a pig?', 'Is it a pig?'], 'guesses': ['pig', 'pig', 'pig'], 'answers': ['no', 'no', 'no'], 'role': 'answerer', 'turnType': 'answer', 'keyword': 'Oak table', 'category': 'things'}, 'status': 'DONE'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# env.render(mode=\"ipython\", width=600, height=500)"
      ],
      "metadata": {
        "id": "QwifCN55FVMd"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d28b9f2a28784963b0836139efce029e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_552f984db9b24abe8cf8a0b3c3be352c",
              "IPY_MODEL_99fbe19d07084443aa86dff3d8c51627",
              "IPY_MODEL_28c6239810a4408180aafd4dcab8d1f8",
              "IPY_MODEL_83bc3ecc29fa4e48a437f4ea09a2e980",
              "IPY_MODEL_e4d7988597994de9923c4d077edec3b0"
            ],
            "layout": "IPY_MODEL_77e4fd7cdd8644c0aa8d30c16dd2bfab"
          }
        },
        "552f984db9b24abe8cf8a0b3c3be352c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a4d667296649b49da969884254ed3e",
            "placeholder": "​",
            "style": "IPY_MODEL_20fd618bfa0849f3b4dc2fecaa0ece26",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "99fbe19d07084443aa86dff3d8c51627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_18e220fb73444e3fb24cd96aa5338739",
            "placeholder": "​",
            "style": "IPY_MODEL_ded686d1611e4312ad50dfef307eddb3",
            "value": ""
          }
        },
        "28c6239810a4408180aafd4dcab8d1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1aea595b3286428d82a02efefe46396d",
            "placeholder": "​",
            "style": "IPY_MODEL_6090da6caf5248498689cfb417dea2cc",
            "value": ""
          }
        },
        "83bc3ecc29fa4e48a437f4ea09a2e980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_32daa8692b164e2dbcf9d94ab2f30836",
            "style": "IPY_MODEL_36ca273ab85b474380223beedaf4df18",
            "tooltip": ""
          }
        },
        "e4d7988597994de9923c4d077edec3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f53b13cbf8c40eab468ade15bb8c53c",
            "placeholder": "​",
            "style": "IPY_MODEL_888a104f44114e3991dfd37fcbdaa6f2",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "77e4fd7cdd8644c0aa8d30c16dd2bfab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "73a4d667296649b49da969884254ed3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20fd618bfa0849f3b4dc2fecaa0ece26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e220fb73444e3fb24cd96aa5338739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded686d1611e4312ad50dfef307eddb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aea595b3286428d82a02efefe46396d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6090da6caf5248498689cfb417dea2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32daa8692b164e2dbcf9d94ab2f30836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ca273ab85b474380223beedaf4df18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3f53b13cbf8c40eab468ade15bb8c53c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888a104f44114e3991dfd37fcbdaa6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}