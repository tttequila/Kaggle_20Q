<!-- # Kaggle_20Q
kaggle 20Q noob team from three academic trashes -->

<a href="https://colab.research.google.com/github/tttequila/Kaggle_20Q/blob/main/LLM_Agent.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## 1. Task Description
ä½¿ç”¨LLMsæ¥è¿›è¡Œç»å…¸çš„20 Questionæ¸¸æˆï¼Œå³é€šè¿‡æœ‰é™é—®ç­”æ¥çŒœæµ‹å‡ºä¸€ä¸ªå¯¹æ–¹é¢„å…ˆé€‰å¥½çš„secret wordã€‚æ¯æ¬¡æ¯”èµ›ä»¥2v2çš„å½¢å¼è¿›è¡Œï¼Œæ¯é˜Ÿå„æœ‰ä¸¤ä¸ªLLMsï¼Œ**ä¸€ä¸ªguesser LLMè´Ÿè´£æ ¹æ®å¯¹æ–¹answerer LLMçš„å›ç­”è¿›è¡Œæé—®**ï¼Œ**å¦ä¸€ä¸ªanswerer LLMåˆ™è´Ÿè´£ç†è§£å¯¹æ–¹é˜Ÿä¼çš„æé—®å¹¶å›ç­”yesæˆ–è€…no**ã€‚

<details>
        <summary><b> Rules </b></summary>

1. æ¸¸æˆä¼šè¢«é™åˆ¶åœ¨20è½®å†…ï¼Œè¶…è¿‡è½®æ•°åŒæ–¹åˆ¤è´Ÿ
2. æé—®é™åˆ¶åœ¨2000ä¸ªå­—ç¬¦å†…
3. å›ç­”é™åˆ¶åœ¨100ä¸ªå­—ç¬¦å†…
4. answereråªèƒ½å›ç­”yesæˆ–è€…no
5. ä»»ä½•è¿è§„è¡Œä¸ºç›´æ¥åˆ¤è´Ÿ

</details>

<details>
        <summary><b> èµ„æº </b></summary>

100G diskï¼Œ16G RAMï¼ŒT4 GPU

</details>

#### 1.1. Summary
åŸºæœ¬ä¸Šæ¥è¯´ï¼Œagentéœ€è¦è‡³å°‘å…·å¤‡ä¸¤ä¸ªåŠŸèƒ½ï¼š1. æ­£ç¡®**ç†è§£é—®é¢˜**å¹¶æ›´å…·secret word**å›ç­”**ï¼›2. æ ¹æ®å¯¹æ–¹çš„å›ç­”æ¥è¿›è¡Œä¸‹ä¸€ä¸ªçŒœæµ‹å’Œæé—®ã€‚è€Œæ ¹æ®çŒœæµ‹å›ç­”é—®é¢˜åˆ™éœ€è¦agentå…·æœ‰è¶³å¤Ÿçš„**ä¿¡æ¯æœé›†**å’Œ**æ¨ç†èƒ½åŠ›**

---

## 2. Methodology
<!-- å…¶å®agentçš„ä»»åŠ¡æœ¬è´¨ä¸Šæ˜¯å‡å°ä¸‹ä¸€æ­¥çš„ç†µï¼ˆæˆ–è€…æ˜¯ç¡®ä¿¡åº¦ï¼‰ï¼šä½œä¸ºguesseræ—¶ï¼Œå¯ä»¥æ˜¯é€‰æ‹©èƒ½æœ€å°åŒ–ç†µçš„æé—®æ–¹æ³•/secrete wordçš„ç‰¹å¾ç‚¹/etcï¼›è€Œä½œä¸ºanswereræ—¶çš„ï¼Œè¿™æ˜¯åœ¨yesæˆ–è€…noå½“ä¸­äºŒé€‰ä¸€ä¸€ä¸ªç½®ä¿¡åº¦æœ€å¤§çš„é€‰é¡¹

è€Œå…·ä½“æ€ä¹ˆå®ç°å¯èƒ½æœ‰å¾ˆå¤šç§æ–¹æ³•ï¼Œå…·ä½“ä¾ç…§game envèƒ½æä¾›çš„æ¸¸æˆä¿¡æ¯ï¼ˆä¾‹å¦‚æˆ‘ä»¬çŸ¥ä¸çŸ¥é“å…¨éƒ¨çš„key wordsè¯è¡¨ï¼‰æ¥ç¡®å®š
> ğŸ’¬
> - é€šè¿‡**prompting engineering**ç®€å•åœ°æ¥é€‰å–LLMè‡ªå·±è®¤ä¸ºç½®ä¿¡åº¦æœ€é«˜çš„ç‰¹å¾ï¼Œå›ç­”ï¼ŒçŒœæµ‹ï¼Œ...
> - é€šè¿‡ä¸€äº›ç»Ÿè®¡ä¸Šçš„æ–¹æ³•æ¥è¡¡é‡ä¸ç¡®å®šæ€§
> - é€šè¿‡ä¸€äº›æœºå™¨å­¦ä¹ çš„æ–¹æ³•æ¥ä¼°è®¡ä¸€ä¸ªæœ€å¤§åŒ–ï¼ˆæœ€å°åŒ–ï¼‰ç½®ä¿¡åº¦ï¼Œä¿¡æ¯å¢ç›Šï¼Œ...çš„é€‰é¡¹
>


#### 2.1. KnowNo

é‚£æ—¢ç„¶éƒ½æåˆ°äº†ç½®ä¿¡åº¦çš„é—®é¢˜äº†ï¼Œåˆšå¥½å¯ä»¥è€ƒè™‘èƒ½ä¸èƒ½ä½¿ç”¨ä¹‹å‰é¢è¯•è¯»åˆ°é‚£ç¯‡paperï¼Œé€šè¿‡ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•æ¥è®©agentèƒ½å¤Ÿè‡ªå·±ä¼°è®¡ä¸ç¡®å®šæ€§æˆ–è€…ç½®ä¿¡åº¦

è¯¥æ–‡ç« æœ¬è´¨æ˜¯è®©robotåœ¨å®é™…ç¯å¢ƒä¸­èƒ½å¤Ÿç¡®å®šæœ‰æ²¡æœ‰æ­§ä¹‰çš„é€‰é¡¹ï¼Œä½†é‡Œé¢æœ‰ç”¨åˆ°ä¸€äº›æ¯”è¾ƒå¥½ç”¨çš„æ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨å¤šé€‰é—®é¢˜ï¼ˆMulti Choice Question&Answerï¼‰æ¥å°†LLMè¾“å‡ºçš„tokençš„ç½®ä¿¡åº¦ä½œä¸ºè¿™ä¸ªé€‰é¡¹çš„ç½®ä¿¡åº¦

è‡³äºå…¶å…·ä½“èƒ½å¦åº”ç”¨è¿›å»ï¼Œå¯èƒ½éœ€è¦æ›´å¤šçš„ä»”ç»†è€ƒè™‘ -->

ç”±äºå®é™…æ¯”èµ›ä¸­æ— æ³•è·å–å®Œæ•´çš„keyword listï¼Œå› æ­¤åŸºæœ¬ä¸ŠLLMæ˜¯éœ€è¦å…·å¤‡ä»é›¶å¼€å§‹è§„åˆ’çš„èƒ½åŠ›çš„ï¼Œåˆå§‹åŒ–å¯ä»¥ä»ç»™å‡ºçš„ä¸‰ä¸ªcategoriesé‡Œé¢åšéšæœºé€‰æ‹©ï¼Œè€Œåé¢åˆ™éœ€è¦å¼€å§‹æ ¹æ®å·²çŸ¥ä¿¡æ¯è¿›è¡Œè§„åˆ’

- **Pure Prompting**: ç›´æ¥é€‰æ‹©æ¯”è¾ƒå¤§çš„æ¨¡å‹è¿›è¡Œéƒ¨ç½²ï¼Œä¾‹å¦‚Gemma-9Bï¼Œç„¶ååˆ©ç”¨CoTçš„æ–¹æ³•ç›´æ¥å¾—åˆ°ç­”æ¡ˆã€‚ä»‹äºå›ç­”æ—¶é—´åªæœ‰60sï¼Œè€ŒGemma-7B *(output_len=100)* åœ¨colabä¸Šæ‰€éœ€è¦çš„æ¨ç†æ—¶é—´å·²ç»é«˜è¾¾45sï¼Œå› æ­¤æˆ‘ä»¬åªèƒ½ä½¿ç”¨ä¸€æ¬¡promptingæ¥ç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼Œæ•´ä¸äº†ä»€ä¹ˆèŠ±æ´»
- **CoT Voting**: è€ƒè™‘åˆ°Gemma-2B *(output_len=100)* çš„æ¨ç†é€Ÿåº¦æå¿«ï¼Œåªéœ€è¦3så·¦å³å³å¯ç”Ÿæˆä¸€æ¬¡responseï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è€ƒè™‘ä½¿ç”¨å¤šè½®ä½temperatureçš„é‡‡æ ·æ¥ç”Ÿæˆä¸åŒçš„æ¨ç†è·¯çº¿ï¼Œç„¶åå†ä½¿ç”¨æŠ•ç¥¨çš„æ–¹æ³•é‡‡æ ·å‡ºä¸€ä¸ªæœ€åˆé€‚çš„æé—®æ–¹æ³•
- **MoE**: åŒæ ·ï¼Œè€ƒè™‘å¯ä»¥åˆ©ç”¨2Bæ¨¡å‹æ¨ç†è¿…é€Ÿçš„ä¼˜åŠ¿ï¼Œå†è¾…ä»¥Mixture of Expertçš„æ–¹æ³•æ¥è¿›è¡Œé«˜è´¨é‡ä¸”å¿«é€Ÿçš„ç”Ÿæˆ
- **å…¶ä»–**: ä¾‹å¦‚åˆ©ç”¨å°çš„LMæ¥å¾—åˆ°å±æ€§çš„embeddingï¼Œç„¶åå†é€šè¿‡ä¸€äº›æ•°å€¼æ–¹æ³•å¾—åˆ°æœ€æœ‰åŒºåˆ†åº¦çš„é—®æ³•ï¼Ÿä¾‹å¦‚è®©Gemmaåˆ†æå‡ºå‰10ä¸ªæœ€èƒ½é™ä½ä¸ç¡®å®šæ€§çš„è¯ï¼Œè®¡ç®—å®ƒä»¬çš„embeddingï¼Œç„¶åä»ä¸­é€‰æ‹©èšç±»sizeæœ€å¤§çš„é‚£ç±»è¯è¿›è¡Œæé—®


---
<!--
## 3. To-do ğŸ“
æš‚æ—¶æ¥è¯´ï¼Œç›®å‰è¿˜åœ¨å½¢æˆæ€è·¯çš„é˜¶æ®µï¼Œä½†æ˜¯æœ‰ä¸€äº›ä¸œè¥¿å¯ä»¥å…ˆå»äº†è§£

- [ ] æ€ä¹ˆéƒ¨ç½²LLM

> - è¿™ä¸ªä¼¼ä¹æœ‰å¾ˆå¤šä¸åŒçš„æ–¹æ³•ï¼Œä¾‹å¦‚Kaggleä¼¼ä¹åŸç”Ÿæ”¯æŒä¸€äº›åˆä½œå•†çš„LLMï¼ˆè¿™é‡Œä¸»è¦æ˜¯Gemmaï¼‰çš„è°ƒç”¨ï¼Œå¦‚æœæˆ‘æƒ³åœ¨è‡ªå·±çš„ç¯å¢ƒä¸‹æµ‹è¯•çš„è¯ï¼ˆæˆ–è€…colabç¯å¢ƒï¼‰ï¼Œå¯èƒ½éœ€è¦è€ƒè™‘åˆ«çš„æ–¹æ³•
> - Kaggleä¹Ÿæä¾›äº†ä¸€äº›åˆ«çš„LLMï¼Œä¾‹å¦‚Llama 3çš„å„ç§åº“çš„æ¨¡å‹å®ç°ï¼Œå¹¶ä¸”ä¾‹å¦‚Llama 3ï¼ŒKaggleä¹Ÿæä¾›äº†Vertex AIï¼ˆä¼¼ä¹æ˜¯Googleæä¾›ç»™ç”¨æˆ·éƒ¨ç½²LLMçš„äº‘ï¼‰çš„è·³è½¬é“¾æ¥ã€‚ä½†å…·ä½“æ€ä¹ˆéƒ¨ç½²è¿˜éœ€è¦è‡ªå·±æ¢ç´¢
> - åˆ«çš„ä¸€äº›å¼€æºæ¨¡å‹æ¯”å¦‚Claudeç­‰ï¼Œå¯ä»¥è‡ªå·±è·å–è‡ªå·±éƒ¨ç½²
> 
> *ä½†è¯·è®°ä½ï¼Œæˆ‘ä»¬åªæœ‰16Gï¼Œåº”è¯¥åªèƒ½éƒ¨ç½²ä¸€äº›7Bå·¦å³çš„LLMï¼Œè€Œä¸”å¯èƒ½éœ€è¦è€ƒè™‘åˆ°ä¼šä¸ä¼šæœ‰åˆ«çš„å°ä¸€ç‚¹çš„è¾…åŠ©æ¨¡å‹éœ€è¦è®­ç»ƒå’Œéƒ¨ç½²*
- [ ] æ€è€ƒä¸€ä¸‹agentçš„å¤§è‡´æ¡†æ¶
- [ ] çœ‹started notebookï¼Œå¯¹agentçš„å®ç°æœ‰ä¸ªå¤§æ¦‚çš„æ¦‚å¿µ
- [ ] çœ‹è®ºæ–‡ï¼Œæˆ–è€…å»æœé›†åˆ«çš„æ€è·¯ï¼ˆChain of Thoughtsï¼‰æ¥çœ‹çœ‹èƒ½ä¸èƒ½è¾¾æˆç›®æ ‡
- [ ] TBC...

---
 -->

## Reference
- KnowNo: https://robot-help.github.io/
- Gemma started notebook: https://www.kaggle.com/code/christianwittmann/llm-20-questions-starter-notebook-fully-documented
- å¦‚ä½•åœ¨Kaggleç¯å¢ƒéƒ¨ç½²LLM (video)ï¼šhttps://www.youtube.com/watch?v=jsCUDeg_Op4
- ä¹‹å‰é¢è¯•ç”¨çš„KnowNoçš„pptï¼šhttps://docs.google.com/presentation/d/180D0WsrutKRSipPYugZ3sYz2Eer1drML/edit?usp=sharing&ouid=116445889014826569768&rtpof=true&sd=true
- å¼€æºLLMæ±‡æ€»ï¼šhttps://www.53ai.com/news/qianyanjishu/1743.html
- Gemma Document: https://ai.google.dev/gemma/docs/pytorch_gemma
- Gemma Cookbook (more details): https://github.com/google-gemini/gemma-cookbook?tab=readme-ov-file
- Advanced Prompting with Gemma: https://github.com/google-gemini/gemma-cookbook/blob/main/Gemma/Advanced_Prompting_Techniques.ipynb
- CoTæ±‡æ€»: https://juejin.cn/post/7204057769493413943
- MoEæ€»ç»“: https://www.53ai.com/news/qianyanjishu/1446.html
- Prompt Engineering Guide: https://www.promptingguide.ai/zh/techniques/tot
- CoTæ±‡æ€»_2: https://zhuanlan.zhihu.com/p/703881352?utm_psn=1797059515520278531



![ä¸»è¦çœ‹reasoningçš„æŒ‡æ ‡](imgs/image.png)
<center><i><b> ä¸»è¦çœ‹reasoningçš„æŒ‡æ ‡ </b></i></center>

----

### To-Do

> æ€»çš„æ€è·¯æ˜¯è®©agentæ¯æ¬¡è¾“å‡ºéƒ½æ˜¯åŸºäºä¸€ä¸ªé€‰å®šå¥½çš„ç‰¹å¾æ¥æé—®ï¼ˆæŸç§ç¨‹åº¦ä¸Šï¼Œå¯ä»¥ç±»æ¯”äºä¸€ä¸ªåƒrandom forestçš„äºŒå‰æ ‘ï¼Œåªä¸è¿‡ä¸æ˜¯ä¸€ä¸ªå›ºå®šå¥½çš„ä»¥åŠé¢„è®­ç»ƒå¥½çš„æ ‘ï¼Œè€Œæ˜¯åŸºäºLLMçš„æ¨ç†å’Œç†è§£å’ŒçŸ¥è¯†æ³¨å…¥ï¼‰
>
>     ğŸ‘‰ä¾‹å¦‚å¯¹æ¯ä¸ªkeywordé€šè¿‡LLMæå–å‡ºä¸€äº›ç‰¹å¾
>       e.g.å¯¹äº keyword: *accent chair*ï¼Œæœ‰{æè´¨, é¢œè‰²ï¼Œå›½å®¶ï¼Œ...}
>           ç„¶åé€‰å‡ºèƒ½æä¾›æœ€å¤§ä¿¡æ¯å¢ç›Šçš„ç‰¹å¾ï¼Œé€šè¿‡promptingè®©LLMæé—®
>     ğŸ‘‰äº¦æˆ–è€…æ˜¯ç›´æ¥é€šè¿‡promptingè®©LLMé€‰æ‹©ä»–è®¤ä¸º
>       å¯ä»¥æœ€å¤§ç¨‹åº¦å‡å°‘ä¸ç¡®å®šæ€§çš„ç‰¹å¾å¹¶æé—®ï¼Œä¾‹å¦‚ä½¿ç”¨CoTç­‰promptingæŠ€å·§     

<!-- - [ ] æ„å»ºæ€è·¯
  - [x] çœ‹çœ‹åˆ«äººä¸Šä¼ çš„notebook
  - [x] çœ‹çœ‹åˆ«çš„prompting basedçš„æ–‡ç« 
  - [x] çœ‹çœ‹æœ‰æ²¡æœ‰åˆ«çš„statistic basedçš„ä¸ºå¤§æ¨¡å‹è¡¡é‡ç½®ä¿¡åº¦çš„æ–‡ç« 
  - [x] è€ƒè™‘ä¸Šé¢è¿™ä¸¤ä¸ªæ–¹æ³•çš„å¯è¡Œæ€§ï¼Ÿ
  - [ ] çœ‹çœ‹[é«˜çº§promptæŠ€å·§](https://github.com/google-gemini/gemma-cookbook/blob/main/Gemma/Advanced_Prompting_Techniques.ipynb)
- [ ] æ€»ä½“çš„agentæ¡†æ¶å’Œæ¯”èµ›éœ€è¦çš„agentæ ¼å¼éœ€è¦ææ˜ç™½
  - [ ] æ¯”èµ›éœ€è¦çš„agentçš„æ¥å£
  - [ ] LLMæœ¬èº«çš„æ¥å£å’Œéƒ¨ç½²
  - [ ] ç”¨æ¥åŒ…è£…agentçš„ç±»çš„ä¸€äº›æ¥å£å’Œéœ€è¦çš„å‡½æ•°ï¼Œä¾‹å¦‚answereræ¨¡å¼å’Œguesseræ¨¡å¼
- [x] å¯ä»¥å¼€å§‹åœ¨æœåŠ¡å™¨ä¸Šæ¯”å¦‚colabä»€ä¹ˆçš„éƒ¨ç½²ä¸ªLLMç©ç©ï¼Œçœ‹çœ‹æ€ä¹ˆä½¿ç”¨LLM
- [x] æ¢ç´¢Gemmaçš„ç”¨æ³• -->

- [ ] çœ‹MoE
  - [ ] MoEå’ŒVoting CoTçš„å·®åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
- [ ] çœ‹ standard CoT
  - [ ] å†™ä¸€ä¸ªprototypeï¼ˆ7Bï¼‰
- [ ] çœ‹ voting CoTW
  - [ ] å†™ä¸€ä¸ªprototypeï¼ˆ2Bï¼‰
  - [ ] ç¯å¢ƒä¸‹å¯ä»¥å¤šçº¿ç¨‹å—

##### Current Work
- [ ] åŠ ä¸€ä¸ªkaggleå’Œcolabçš„åˆå§‹åŒ–çš„åˆ‡æ¢å‚æ•°
- [ ] å†™ä¸€ä¸ªæ ¼å¼åŒ–çš„formatter
- [ ] åŠ attribute listï¼Œç„¶åæ ¹æ®attribute listè‡ªåŠ¨formatæ–°çš„prompt
- [ ] decay temperature / top_k / top_p
- [x] CoT prompt
  - [ ] æäº¤æ ¼å¼
- [ ] voting MoE

#### Experiment recording

<details>
        <summary><b> Single SLM with multiple CoT examples </b></summary>


- 1 question deduction,**150** output length
  - 72sâŒ, no indication of answerâŒ
- 3 question deduction,**150** output length
  - 72sâŒ, no indication of answerâŒ
- **6** question deduction,**150** output length
  - 83sâŒ, completed answer and indicatorâœ…
- 3 question deduction,**100** output length
  - 52sâœ…, incompleted responseâŒ
  (maybe we can limit the length of reasoning within 100 characters)
- **6** question deduction,**100** output length
  - 59sâœ…, incompleted responseâŒ

---

**ğŸ‘‡ Try to downsize the length of the CoT example. (better few shot cases and system prompt)**

---

- **6** question deduction, **100** output length 
  - 51sâœ…, completed and fair reasoningâœ…
- **6** question deduction, **150** output length
  - 68sâŒ, similar result to aboveâœ…

---

**ğŸ‘‡ Apparent path dependence, maybe we need multiple deductions of different cases instead of all steps within one game**

---
</details>
