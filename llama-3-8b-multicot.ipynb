{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61247,"databundleVersionId":8550470,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import and Load Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%bash\ncd /kaggle/working\npip install -U -t /kaggle/working/submission/lib transformers\npip install -U -t /kaggle/working/submission/lib accelerate\npip install -i https://pypi.org/simple/ -U -t /kaggle/working/submission/lib bitsandbytes\npip cache purge","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(0, \"/kaggle/working/submission/lib/\")\n# print(sys.path)\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\n\nmodel_name = \"abacusai/Llama-3-Smaug-8B\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quanty_type = \"fp4\", \n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quanty = True\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config = bnb_config,\n    torch_dtype = torch.float16,\n    device_map = \"cuda\",\n    trust_remote_code = True,\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel.save_pretrained(\"/kaggle/working/submission/weights\")\ntokenizer.save_pretrained(\"/kaggle/working/submission/weights\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile submission/main.py\nimport os\nimport sys\n\nKAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\nif not os.path.exists(KAGGLE_AGENT_PATH):\n    KAGGLE_AGENT_PATH = \"/kaggle/working/\"\n    \nsys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, \"submission/lib\"))\n\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom kaggle_secrets import UserSecretsClient\nimport shutil\nfrom typing import Iterable\nfrom typing import Any, List, Optional, Sequence, Tuple, Union\nfrom ast import parse\nimport contextlib, time, random, itertools, re\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\n\n\nMACHINE_TYPE = 'cuda'\nagent = None\n    \n# configering setting\nsys_prompt_asker = 'You are an AI assistant designed to play the 20 Questions game. \\\nIn each round of the game, choose an attribute most likely to aid your deduction and ask a yes-no question based on it. \\\nYour response should be generated with step-by-step reasoning. Ensure that the question you generate has not been asked before and that its attribute is not shown in the known information list. Consider whether this attribute or a similar question has been asked before selecting key attributes. \\\nAn unavailable question will cause seriouse problem so think more thoroughly before responsing. \\\nOnce you believe that the key attribute is available, the most helpful attribute among effective ones provides the maximum information gain, meaning it significantly reduces the entropy of your guess, regardless of whether the answer is **yes** or **no**. Finally using this attribute, ask a question in English.'\n\nsys_prompt_answerer = f'You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing. Here is an example of answering a yes-no question:'\n\nfew_shot_examples_answerer = [\n    \n'''\nThe keyword is Sydney in the category place. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.\n\n''',\n     \n'''\nQuestion: Is it a place?\n**yes**\nSydney is a city, which is a type of place. This is why the answer to the question \"Is it a place?\" is yes.\n''',\n     \n'''\nQuestion: Is it located in the Southern Hemisphere?\n**yes**\nSydney is a city in Australia, which is in the Southern Hemisphere. Therefore, the answer to your question is yes.\n''',\n     \n'''\nQuestion: Is it a capital city?\n**no**\nAlthough Sydney is a major city in Australia, the capital city of Australia is Canberra. Therefore, the answer to your question is no.\n''',\n     \n     \n'''\nQuestion: Is it a well-known tourism city?\n**yes**\nSydney is famous for its landmarks such as the Sydney Opera House, the Harbour Bridge, and its beautiful beaches, making it a major tourist destination. Therefore, the answer to your question is yes.\n'''\n                              \n]\n\nfew_shot_examples_asker = [\n    \n[# Round 1 | Keyword: Yangtze River\n'''\nKnown information: [\"is it a country? --> no\", \"is it a city? --> no\"]\n**Key attribute**: \"man-made structure\" \n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is it a man-made structure?\" \n**Reasoning**:\nsince following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \nMan-made vs. Natural: This question helps to differentiate between natural landmarks (e.g., Grand Canyon) and man-made structures (e.g., Eiffel Tower). \nBroad Categories: Man-made structures include a wide range of possibilities (e.g., buildings, monuments), whereas cities are all man-made but represent a different category. \n''',\n\n'''\nKnown information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\"]\n**Key attribute**: \"in Asia\" \n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is it located in Asia?\" \n**Reasoning**:\nsince following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \nGeographic Focus: Identifying the continent will significantly narrow down the possible natural landmarks. \nLarge Landmarks: Asia has several major natural landmarks (e.g., Mount Everest, Great Wall).\n''',\n\n'''\nKnown information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\", \"is it a river? --> yes\"]\n**Key attribute**: \"longest river in China\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is it the longest river in China?\"\n**Reasoning**:\nsince following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \nLength-Specific Focus: Knowing whether it is the longest river will help confirm or eliminate the Yangtze River.\nMajor Rivers: The Yangtze River is the longest river in China, followed by the Yellow River.\nEffective Split: This question will help confirm or deny one of the most prominent landmarks in China, providing a clear yes/no split.\n'''],\n\n\n[# Round 2 | Keyword: Congo\n'''\nKnown information: [\"is it a country? --> yes\"]\n**Key attribute**: \"in Europe\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this country in Europe?\"\n**Reasoning**:\nsince following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \nContinental Focus: Knowing the continent will help significantly narrow down the list of possible countries.\nEffective Reduction: Europe has many countries, so confirming or eliminating Europe will reduce the search space.\n''',\n\n'''\nKnown information: [\"is it a country? --> yes\", \"is it in Europe? --> no\", \"is it in Asia? --> no\", \"is it in Africa? --> yes\", \"is it in Northern Africa? --> no\", \"is it in Eastern Africa? --> no\", \"is it in Western Africa? --> no\", \"is it in Southern Africa? --> yes\"]\n**Key attribute**: \"landlocked country\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this country landlocked?\"\n**Reasoning**:\nTo further narrow down the possibilities within Southern Africa, I will focus on another well-known country in that region.\nGeographical Focus: Knowing whether the country is landlocked will significantly narrow down the possibilities within Southern Africa.\nEffective Reduction: There are several landlocked countries in Southern Africa, so confirming or eliminating this will help focus the search.\n''',\n\n'''\nKnown information: [\"is it a country? --> yes\", \"is it in Europe? --> no\", \"is it in Asia? --> no\", \"is it in Africa? --> yes\", \"is it in Northern Africa? --> no\", \"is it in Eastern Africa? --> no\", \"is it in Western Africa? --> no\", \"is it in Southern Africa? --> yes\", \"is it landlocked? --> no\", \"is Portuguese its an official language? --> no\"]\n**Key attribute**: \"borders the Indian Ocean\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Does this country border the Indian Ocean?\"\n**Reasoning**:\nsince following information havn't been confirmed according to the known information list, so it's legal and avaliable to consider that: \nGeographic Focus: Knowing whether the country borders the Indian Ocean can help narrow down the options.\nBalanced Distribution: This question provides a clear yes/no split, effectively narrowing down the search.\n '''],\n \n[# round 3 | Keyword: Ryan \n'''\nKnown information: [\"is it a place? --> no\", \"is it a person? --> yes\"]\n**Key attribute**: \"a historical figure\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this person a historical figure?\"\n**Reasoning**:\nTime Frame: Identifying whether the person is historical can significantly narrow down the possibilities.\nBalanced Distribution: This question provides a clear yes/no split, guiding the search effectively.\n''',\n\n'''\nKnown information: [\"is it a place? --> no\", \"is it a person? --> yes\", \"is it a historical figure? --> no\", \"is it involved in the entertainment industry? --> yes\", \"is it primarily known for their work in music? --> no\", \"is it primarily known for their work as an actor? --> yes\", \"has it won an Academy Award (Oscar)? --> no\"]\n**Key attribute**: \"primarily known for television work\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this person primarily known for their work in television?\"\n**Reasoning**:\nMedium Focus: Identifying whether the person is known for television can help narrow down the possibilities.\nBalanced Distribution: This question provides a clear yes/no split, effectively guiding the search.\n''',\n\n'''\nKnown information: [\"is it a place? --> no\", \"is it a person? --> yes\", \"is it a historical figure? --> no\", \"is it involved in the entertainment industry? --> yes\", \"is it primarily known for their work in music? --> no\", \"is it primarily known for their work as an actor? --> yes\", \"has it won an Academy Award (Oscar)? --> no\", \"is it primarily known for their work in television? --> no\", \"is it primarily known for their work in action movies? --> yes\", \"is it associated with a major action movie franchise? --> yes\"]\n**Key attribute**: \"known for science fiction action movies\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this person known for their work in science fiction action movies?\"\n**Reasoning**:\nGenre Specificity: Identifying whether the person is known for science fiction action movies can help narrow down the possibilities.\nEffective Reduction: This helps distinguish between different types of action movie genres, such as sci-fi, fantasy, or military.\n'''],\n\n[# round 4 | Keyword: Noosa\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\"]\n**Key attribute**: \"a capital city\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is it a capital city?\"\n**Reasoning**:\nGeographic Focus: This question helps determine if the city is a capital, significantly narrowing the possibilities.\nEffective Reduction: If the answer is yes, it focuses on capital cities, eliminating all non-capital cities. If no, it eliminates all capital cities from consideration.\nContext Relevance: Knowing whether the city is a capital helps tailor subsequent questions to specific types of cities.\n''',\n\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes.\"]\n**Key attribute**: \"in the Southern Hemisphere\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this city in the Southern Hemisphere?\"\n**Reasoning**:\nHemispheric Focus: This question splits the world into two large, nearly equal parts, effectively narrowing down possibilities.\nBalanced Distribution: The Earth is divided evenly by the equator, providing a clear yes/no split that maximizes information gain.\n''',\n\n\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes\", \"is it in Africa? --> no\", \"is it in South America? --> no\", \"is it in Australia or Oceania? --> yes\", \"is it in Australia? --> yes\", \"is it a coastal city? --> yes\"]\n**Key attribute**: \"a well-known tourist destination\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this city a well-known tourist destination?\"\n**Reasoning**:\nTourism Focus: This question helps determine if the city is popular with tourists, which can narrow down the list of coastal cities.\nEffective Reduction: If the answer is yes, it focuses on well-known tourist cities, eliminating less-known cities. If no, it narrows down to less-touristic coastal cities.\nContext Relevance: Many of Australia's coastal cities are also popular tourist destinations, making this an important distinction.\n''',\n\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes\", \"is it in Africa? --> no\", \"is it in South America? --> no\", \"is it in Australia or Oceania? --> yes\", \"is it in Australia? --> yes\", \"is it a coastal city? --> yes, \"is a well-known tourist destination? --> yes\", \"is it Gold Coast? --> no\", \"is it in New South Wales? --> no\", \"is it in Queensland? --> yes\", \"is it associated with the Great Barrier Reef? --> no\"]\n**Key attribute**: \"popular for its beaches\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this city popular for its beaches?\"\n**Reasoning**:\nTourism Focus: Identifying if the city is known for its beaches can help narrow down the possibilities.\nContext Relevance: Many coastal cities in Queensland are known for their beaches, making this a significant distinction.\nBalanced Distribution: Coastal versus inland tourist destinations provide a clear yes/no split.\n''',\n\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> yes\", \"is it a country? --> no\", \"is it a city? --> yes\", \"is it a capital city? --> no\", \"is it in the Southern Hemisphere? --> yes\", \"is it in Africa? --> no\", \"is it in South America? --> no\", \"is it in Australia or Oceania? --> yes\", \"is it in Australia? --> yes\", \"is it a coastal city? --> yes, \"is a well-known tourist destination? --> yes\", \"is it Gold Coast? --> no\", \"is it in New South Wales? --> no\", \"is it in Queensland? --> yes\", \"is it associated with the Great Barrier Reef? --> no\", \"is it popular for its beaches? --> yes\"]\n**Key attribute**: \"located on the Sunshine Coast\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is this city located on the Sunshine Coast?\"\n**Reasoning**:\nRegional Focus: Identifying if the city is on the Sunshine Coast can significantly narrow down the possibilities.\nContext Relevance: The Sunshine Coast is known for its beach destinations, making this a significant distinction.\n'''],\n\n[# round 5 | Keyword: Gym Mat\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> no\", \"is it a thing? --> yes\"]\n**Key attribute**: \"a technological device\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is it a technological device?\"\n**Reasoning**:\nCategory Specificity: Identifying whether the thing is a technological device helps narrow down the possibilities.\nEffective Reduction: This helps focus on a specific type of thing.\n''',\n\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> no\", \"is it a thing? --> yes\", \"is it a technological device? --> no\"]\n**Key attribute**: \"found in nature\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is it something found in nature?\"\n**Reasoning**:\nCategory Specificity: Identifying whether the thing is natural helps narrow down the possibilities.\nBalanced Distribution: This question provides a clear yes/no split, guiding the search effectively.\n''',\n\n'''\nKnown information: [\"is it a person? --> no\", \"is it a place? --> no\", \"is it a thing? --> yes\", \"is it a technological device? --> no\", \"can it be found in nature? --> no\"]\n**Key attribute**: \"found in households\"\n**Redundent attribute**: no, since following information havn't been confirmed according to the known information list.\n**Question**: \"Is it something found in households?\"\n**Reasoning**:\nCategory Specificity: Identifying whether the thing is commonly found in households helps narrow down the possibilities.\nEffective Reduction: This helps focus on a specific type of man-made object.\nBalanced Distribution: This question provides a clear yes/no split, guiding the search effectively.\n''']\n]\n\nfew_shot_examples_guess = [\n'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\"]\\n\\\nGiven these clues, it is likely a natural landmark rather than a city or a man-made structure. An example of a well-known natural landmark is the Grand Canyon.\\\n**Guess**: \"Grand Canyon\"'\n\n'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\"]\\n\\\nGiven these clues, it is likely a natural landmark outside North America. An example of a famous natural landmark outside North America is Mount Everest.\\\n**Guess**: \"Mount Everest\"'\n \n'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\"]\\n\\\nGiven these clues, it is likely a natural landmark in Asia. A famous natural landmark in Asia is the Himalayas.\\\n**Guess**: \"the Himalayas\"'\n \n'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\"]\\n\\\nGiven these clues, it is likely a famous natural landmark in China. An example of such a landmark is the Mekong River.\\\n**Guess**: \"the Mekong River\"'\n \n'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\"]\\n\\\nGiven these clues, it is likely a natural landmark in China that is not a mountain. An example of such a landmark could be the Tianchi Lake.\\\n**Guess**: \"the Tianchi Lake\"'\n \n'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\", \"is it a river? --> yes\"]\\n\\\nGiven these clues, a very famous river in China is the Yellow River.\\\n**Guess**: \"the Yellow River\"',\n                          \n'Known information: [\"is it a country? --> no\", \"is it a city? --> no\", \"is it a landmark? --> yes\", \"is it a man-made structure? --> no\", \"is it in North America? --> no\", \"is it in Aisa? --> yes\", \"is it in China? --> yes\", \"is it a river? --> yes\", \"is it the longest river in China? --> yes\"]\\n\\\nGiven these clues, it should be the longest river in China which is the Yangtze River.\\\n**Guess**: \"the Yangtze River\"']\n\n    \ndef interleave_unequal(x, y):\n    '''\n        Interleave two lists of unequal length.\n    '''\n    return [\n        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n    ]\n\nclass PromptFormatter:\n    \n    '''\n        formatter class to format the prompt text for the model. \n        A general idea is \n    '''\n    \n    _bos = '<|begin_of_text|>'\n    _eos = '<|end_of_text|>'\n    _end_of_turn = '<|eot_id|>'\n    _start_header = '<|start_header_id|>'\n    _end_header = '<|end_header_id|>'\n        \n    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n        self._system_prompt = system_prompt\n        self._few_shot_examples = few_shot_examples\n        self._template_sys = f\"{self._start_header}system{self._end_header}\\n\\n{{}}{self._end_of_turn}\"\n        self._template_user = f\"{self._start_header}user{self._start_header}\\n\\n{{}}\"\n        self._template_model = f\"{self._start_header}assistant{self._start_header}\\n\\n{{}}\"\n        self._all_prompt = self._bos\n        # if sample_num is not None:\n        #   self.sample_num = sample_num\n        # elif self._few_shot_examples is not None:\n        #   self.sample_num = len(few_shot_examples)\n        # else:\n        #   self.sample_num = None\n\n        self.reset()\n\n    def __repr__(self):\n        return self._all_prompt\n        \n    def reset(self):\n        self._all_prompt = self._bos\n        # if system prompt is provided, add it to the prompt\n        if self._system_prompt is not None:\n            self._all_prompt += self._template_sys.format(self._system_prompt)\n        # same for few shot examples\n        if self._few_shot_examples is not None:\n            # self.add_rounds(self._few_shot_examples, start_agent='user')\n            # self.add_new_round('user', 'Here are some examples of analyzing with causal reasoning:', True)\n            # for example in random.sample(self._few_shot_examples, self.sample_num):\n            \n            self._all_prompt += self._template_user.format('Here are some examples of analyzing with reasoning step by step (they may or may not be continuous). Remember, they are just examples, please do not imitate its asking strategy::\\n\\'\\'\\'\\n')\n            \n            for num, example in enumerate(self._few_shot_examples):\n                self._all_prompt += f'  {num+1}. {example.strip()}\\n'\n              \n            self._all_prompt += f'\\'\\'\\'{self._end_of_turn}'\n    \n        \n    def add_user_round(self, user_prompt: str):\n        # add user round to the prompt\n        self._all_prompt += self._template_user.format(user_prompt)\n        self._all_prompt += self._end_of_turn\n\n    def add_agent_round(self, model_response: str):\n        self._all_prompt += self._template_model.format(model_response)\n        self._all_prompt += self._end_of_turn\n    \n    def add_rounds(self, rounds: Iterable, start_agent: str):\n        '''\n            Apply a sequence of rounds to the formatter, starting with the specified agent.\n        '''\n        formatters = [self.add_agent_round, self.add_user_round] if start_agent == 'model' else [self.add_user_round, self.add_agent_round] # here, self.model and self.user are functions definded above\n        formatters = itertools.cycle(formatters)\n        for fmt, round in zip(formatters, rounds):\n            fmt(round)\n        return self\n    \n    def add_new_round(self, player: str, prompt:str = None, end_token: bool = False):\n        \n        # header and prompt if provided\n        if player == 'model':\n            self._all_prompt += self._template_model.format(prompt if prompt is not None else '')\n        elif player == 'user':\n            self._all_prompt += self._template_user.format(prompt if prompt is not None else '')\n        else:\n            raise ValueError(f\"Unknown player type: {player}\")\n\n        # closure of the round\n        if end_token:\n            self._all_prompt += f\"{self._end_of_turn}\"\n            \n        \n# Agent Definition\nclass GemmaAgent:\n    def __init__(self, model_variant='8b-chat-hf', device='cuda', output_len=200, system_prompt=None, few_shot_examples=None):\n        # model initialization\n        self.device = device\n        self.model_variant = model_variant    \n            \n        KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n        if os.path.exists(KAGGLE_AGENT_PATH):\n            # model_path = os.path.join(KAGGLE_AGENT_PATH, f\"llama-3/transformers/{self.model_variant}/1\")\n            model_path = os.path.join(KAGGLE_AGENT_PATH, f\"submission/weights\")\n        else:\n            # model_path = f\"/kaggle/input/llama-3/transformers/{self.model_variant}/1\"\n            model_path = '/kaggle/working/submission/weights'\n        \n            \n#         # 8bit configuration\n#         bnb_config = BitsAndBytesConfig(\n#             load_in_8bit = True,\n#             bnb_8bit_quanty_type = \"fp4\", \n#             bnb_8bit_compute_dtype=torch.float16,\n#             bnb_8bit_use_double_quanty = True,\n#         )\n        \n        # 4bit configuration\n        bnb_config = BitsAndBytesConfig(\n        load_in_4bit = True,\n        bnb_4bit_quanty_type = \"fp4\", \n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quanty = True,\n        )\n        \n            \n        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code = False)\n        self.model = AutoModelForCausalLM.from_pretrained(model_path, \n                                                          quantization_config = bnb_config, \n                                                          torch_dtype=torch.bfloat16, \n                                                          device_map=self.device, \n                                                          trust_remote_code = False)\n        self.id_eot = self.tokenizer.convert_tokens_to_ids([\"<|eot_id|>\"])[0]        \n    \n            \n        self.round_num = 0\n        self.known_info = []\n        self.last_key_attribute = None\n        self.last_guess = None\n        self.output_len = output_len\n        \n        # formatter arguments   \n        self.system_prompt = system_prompt\n        self.few_shot_examples = few_shot_examples\n    \n    def _reset(self):\n        self.round_num = 0\n        self.known_info = []\n        self.last_key_attribute = None\n        self.last_guess = None\n        self.output_len = output_len\n        \n        if hasattr(self, 'categories'):\n            self.categories = ['person', 'thing', 'place']\n        \n    def _model_generate(self, prompt):\n        # encode input\n        inp_ids = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n        # generate response    \n        out_ids = self.model.generate(**inp_ids,max_new_tokens=self.output_len).squeeze()\n        # decode generated response\n        start_gen = inp_ids.input_ids.shape[1]\n        out_ids = out_ids[start_gen:]\n        # find end of text token, if exits stop decoding, else decode all\n        if self.id_eot in out_ids:\n            stop = out_ids.tolist().index(self.id_eot)\n            out = self.tokenizer.decode(out_ids[:stop])\n        else:\n            out = self.tokenizer.decode(out_ids)\n            \n        return out\n\n\n    def _parse_response(self, response : str):\n      raise NotImplementedError\n  \n    def _format_prompt(self, obs):\n      raise NotImplementedError\n\n\nclass GemmaAgent_Answer(GemmaAgent):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # set up few_shot_examples\n        self.formatter = PromptFormatter(system_prompt=self.system_prompt,\n                                        few_shot_examples=self.few_shot_examples)\n\n    def _parse_response(self, response : str):\n        pattern = re.compile(r'\\*\\*([^*]+)\\*\\*', re.DOTALL)\n        matches = pattern.findall(response.lower())\n        \n        flag_no = 'no' in matches\n        flag_yes = 'yes' in matches\n        \n        # if both yes and no are in the response, randomly choose one\n        if flag_no and not flag_yes:\n            ret = 'no'\n        elif flag_yes and not flag_no:\n            ret = 'yes'\n        else:\n            ret = random.choice(['yes', 'no'])\n        \n        return ret\n\n    def _format_prompt(self, obs):\n        self.formatter.reset()\n        self.formatter.add_user_round(f'Remember how to use CoT as above and the format of answering. Now let us play 20 Questions. You are playing the role of the Answerer. The keyword is {obs[\"keyword\"]} in the category {obs[\"category\"]}.')\n        # add played rounds\n        rounds = interleave_unequal(obs[\"questions\"], obs[\"answers\"])\n        self.formatter.add_rounds(rounds, start_agent='user')\n        self.formatter.add_user_round(f'The keyword is {obs[\"keyword\"]} in the category {obs[\"category\"]}. Give yes-or-no answer and surround your answer with double asterisks, like **yes** or **no**.')\n        # start of model response\n        self.formatter.add_new_round('model', f'Question: {obs[\"questions\"][-1]}', False)\n        \n    def __call__(self, obs, cfg=None):\n        # print(obs['questions'])\n        self._format_prompt(obs)\n        prompt = str(self.formatter)\n        # print(prompt)\n        response = self._model_generate(prompt)\n        print(f'===> Turn Type: {obs[\"turnType\"]}\\nResponse: {response}')\n        return self._parse_response(response)\n\n\nclass GemmaAgent_Guesser(GemmaAgent):\n    def __init__(self, *args, **kwargs):\n        # start = time.time()\n        # set up general configurations\n        super().__init__(*args, **kwargs)\n        # set up few_shot_examples\n        self.few_shot_exmaples_ask = self.few_shot_examples[0]\n        self.few_shot_exmaples_guess = self.few_shot_examples[1]\n        # agent args\n        self.formatter = PromptFormatter(system_prompt=self.system_prompt, \n                                        few_shot_examples=self.few_shot_exmaples_guess)\n        # print(f'Initialization Time: {time.time()-start}s')\n        self.categories = ['person', 'thing', 'place']\n\n        \n    \n    def _parse_response(self, response : str):\n        '''\n            parse the response into a dictionary.\n            may contain three keys: key_attribute, question, guess and their value respectively.\n            e.g.: {\"key_attribute\": 'a country', \"question\": 'Is it a country?'} for a parsed asker response.\n        '''\n        pattern = re.compile(r'\\*\\*([^*]+)\\*\\*:?\\s*(.*?)(?=\\*\\*|$)', re.DOTALL)\n        matches = pattern.findall(response.lower())\n        parse_dict = {'key attribute':None, 'question':None, 'guess':None}\n        for k, v in matches:\n            v = v.strip('\\n\\'\\\"')\n            if ('attr' in k) and (parse_dict['key attribute'] == None):\n                parse_dict['key attribute'] = v\n            elif ('ques' in k) and (parse_dict['question'] == None):\n                parse_dict['question'] = v\n            elif ('guess' in k) and (parse_dict['guess'] == None):\n                parse_dict['guess'] = v\n\n        return parse_dict\n    \n    def _format_prompt(self, obs):\n        if obs[\"turnType\"] == 'ask':\n          self.formatter._few_shot_examples = random.choice(self.few_shot_exmaples_ask)\n        if obs[\"turnType\"] == 'guess':\n          self.formatter._few_shot_examples = self.few_shot_exmaples_guess\n        # reset formatter\n        self.formatter.reset()\n        self.formatter.add_user_round('Remember how to response with reasoning as above and the format of answering, now let us play a new game from the begining.')\n        # add played rounds\n        rounds = interleave_unequal(obs[\"questions\"], obs[\"answers\"])\n        self.formatter.add_rounds(rounds, start_agent='model')\n        if obs[\"turnType\"] == 'ask':\n            self.formatter.add_user_round('Now it is your turn to ask a question. Please construct a new question with chain of thought. Please consider **redundent attribute** step by step and ensure that your chosen attribute is not redundent, which means that your attribute is not redundent and should not be asked before. Baiscally it should follows the format within 100 words as following: **Key attribute**:\"a summarized attribute about your question\"\\n**Redundent**:\"whether and why it is a key attribute that you have not asked before\"\\n**Question**:\"a yes-no question deducted from your reasoning\"\\n**Reasoning**:\"your reasoning about why this attribute is avaliable and the most helpful\"')\n        elif obs[\"turnType\"] == 'guess':\n            self.formatter.add_user_round('Now guess the keyword based on your analysis with reasoning and known information. And surround a pointer of guess with double asterisks (**?**) and your guessed keyword with doublr quotation markers (\"?\") in the end. The final format should looks like:\\nyour reasoning\\n**Guess**: \"your guess\"')\n        # start of model response\n        self.formatter.add_agent_round(f\"Okay, i will analyze the next question step by step and follow your format.\\nGiven information: {str(self.known_info)}\")             \n\n    def __call__(self, obs, cfg=None):\n        '''\n            Main function to interact with the model. \n                1. update known information based on the observation and round number\n                2. format the prompt with the observation\n                3. generate response from the model\n                4. parse the response and update information if needed\n        '''\n\n        if obs[\"turnType\"] == 'ask': \n            print(f\"=========== round: {self.round_num} | last key attr: {self.last_key_attribute}===========\")\n            self.round_num += 1\n            \n            # the category still remains unknown\n            if isinstance(self.categories, list) and len(self.categories) > 1:\n                # for the first round, randomly choose an attribute as initialization\n                self.last_key_attribute = random.choice(self.categories)\n                # kick out the selected key attribute from the categories\n                self.categories = list(set(self.categories) - set([self.last_key_attribute]))\n                response = f'Is it a {self.last_key_attribute}?'\n                return response\n            \n            # Formatting prompt with observations\n            self._format_prompt(obs)\n            prompt = str(self.formatter)\n            # debug\n            print(f\"===> Turn Type: {obs['turnType']}\")\n            print(\"==> Known Info:\", self.known_info)\n            # Getting response from LLM\n            response = self._model_generate(prompt)   \n            print(f'=> Response: {response}')\n            \n            # parse response and update information if needed\n            parse_dict = self._parse_response(response)\n            # print(f'\\nParse_dict: {parse_dict}')\n            # if in an ask turn, try to grab the key attribute from the response and update last key attribute for the next information updating\n            # successfully grab the key attribute from the response\n            if parse_dict['key attribute']:\n                last_key_attribute = parse_dict['key attribute'].lower()\n                last_key_attribute = last_key_attribute.replace('is not ', '')\n                last_key_attribute = last_key_attribute.replace('is ', '')\n                self.last_key_attribute = last_key_attribute\n            # no key attribute parsed from the response, directly use question as key attribute\n            elif parse_dict['question']:\n                self.last_key_attribute  = parse_dict['question']\n                ret = parse_dict['question']\n                return ret\n            # worst case, there is neither key attribute nor question parsed from the response, randomly choose an attribute\n            else:\n                random_alphabet = random.choice('abcdefghijklmnopqrstuvwxyz')\n                ret = f'is it started with alphabet {random_alphabet}?'\n                self.last_key_attribute = f'started with alphabet {random_alphabet}'\n                return ret\n\n            # parsed response has question, use question as response\n            if parse_dict['question']:\n                ret = parse_dict['question']\n            # parsed response has no question but have key attribute, use key attribute as question\n            else:\n\n                ret = f'is it {self.last_key_attribute}?'   \n            return ret\n        # if in a guess turn, try to grab the guess from the response and update last guess for the next information updating\n        elif obs[\"turnType\"] == 'guess':\n            last_question = obs['questions'][-1]\n            # update information\n            if isinstance(self.categories, list) and len(self.categories) > 0:\n                # if it is the second round, grab the answer and update known information\n                last_answer = obs[\"answers\"][-1]\n                # can determine the category\n                if last_answer == 'yes':\n                    self.known_info.append(f'is it a {self.last_key_attribute}? --> yes')\n                    self.categories = self.last_key_attribute\n                # the category is the one left in the category list\n                elif len(self.categories) == 1:\n                    self.known_info.append(f'is it a {self.last_key_attribute}? --> no')\n                    self.categories = self.categories[0]\n                    self.known_info.append(f'is it a {self.categories}? --> yes')\n                # there are still more than one categories left\n                else:\n                    self.known_info.append(f'is it a {self.last_key_attribute}? --> no')                \n            else:\n                # other rounds, update known information\n                last_answer = obs['answers'][-1]\n                self.known_info.append(f'{last_question} --> {last_answer}')\n                # if last_answer == 'yes':\n                    # self.known_info.append(f'{last_question} --> yes')\n                # else:\n                    # self.known_info.append(f'is not {self.last_key_attribute}')\n            \n            # Formatting prompt with observations\n            self._format_prompt(obs)\n            prompt = str(self.formatter)\n            print(f\"===> Turn Type: {obs['turnType']}\")\n            print(\"==> Known Info:\", self.known_info)\n            \n            # print(\"++++++++++++++++++++++++++++++\\n\", prompt, \"\\n++++++++++++++++++++++++++++++\")\n            \n            # Getting response from LLM\n            response = self._model_generate(prompt)   \n            print(f'=> Response: {response}')\n            \n            # parse response and update information if needed\n            parse_dict = self._parse_response(response)\n            # print(f'\\nParse_dict: {parse_dict}')\n            if parse_dict['guess']:\n                self.last_guess = parse_dict['guess']\n                ret = parse_dict['guess']\n            # if there is no guess parsed from the response, return empty string\n            else:\n                ret = ''\n                \n            return ret\n        else:\n            raise ValueError('Invalid turnType.')\n    \n# Simulation API\ndef get_agent(name):\n    global agent\n    \n    if agent is None and name == 'questioner':\n        agent = GemmaAgent_Guesser(device=MACHINE_TYPE,\n                                   output_len=300, \n                                   system_prompt=sys_prompt_asker, \n                                   few_shot_examples=[few_shot_examples_asker, few_shot_examples_guess])\n    elif agent is None and name == 'answerer':\n        agent = GemmaAgent_Answer(device=MACHINE_TYPE,\n                                  output_len=150, \n                                  system_prompt=sys_prompt_answerer,\n                                  few_shot_examples=few_shot_examples_answerer)\n    assert agent is not None, 'Agent not found!'\n    return agent\n\ndef get_fn(obs, config):\n#     start = time.time()\n\n    # print(f\"\\nStrp: {obs['step']}\")\n    # print(agent)\n\n    if obs['turnType'] == \"ask\":\n        response = get_agent('questioner')(obs)\n    elif obs['turnType'] == \"guess\":\n        response = get_agent('questioner')(obs)\n    elif obs['turnType'] == \"answer\":\n        response = get_agent('answerer')(obs)\n\n    if response is None or len(response) <= 1:\n        return \"yes\"\n    else:\n        # print(f'TOTAL TIME: {time.time()-start}s')\n        # print(f'Turn Type: {obs[\"turnType\"]}\\nResponse: {response}')\n        return response","metadata":{"execution":{"iopub.status.busy":"2024-08-07T19:58:55.115270Z","iopub.execute_input":"2024-08-07T19:58:55.115534Z","iopub.status.idle":"2024-08-07T19:58:57.429916Z","shell.execute_reply.started":"2024-08-07T19:58:55.115512Z","shell.execute_reply":"2024-08-07T19:58:57.428656Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install pigz pv > /dev/null","metadata":{"execution":{"iopub.status.busy":"2024-08-07T20:04:51.239940Z","iopub.status.idle":"2024-08-07T20:04:51.240425Z","shell.execute_reply.started":"2024-08-07T20:04:51.240172Z","shell.execute_reply":"2024-08-07T20:04:51.240192Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . \n# -C /kaggle/input/ gemma/pytorch/7b-it-quant/2","metadata":{"execution":{"iopub.status.busy":"2024-08-07T20:04:51.241871Z","iopub.status.idle":"2024-08-07T20:04:51.242328Z","shell.execute_reply.started":"2024-08-07T20:04:51.242091Z","shell.execute_reply":"2024-08-07T20:04:51.242111Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}